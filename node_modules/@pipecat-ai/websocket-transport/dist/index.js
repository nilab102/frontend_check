var $fkNis$dailycodailyjs = require("@daily-co/daily-js");
var $fkNis$pipecataiclientjs = require("@pipecat-ai/client-js");
var $fkNis$events = require("events");
var $fkNis$protobuftsruntime = require("@protobuf-ts/runtime");
var $fkNis$xlaw = require("x-law");


function $parcel$export(e, n, v, s) {
  Object.defineProperty(e, n, {get: v, set: s, enumerable: true, configurable: true});
}

function $parcel$interopDefault(a) {
  return a && a.__esModule ? a.default : a;
}

$parcel$export(module.exports, "WavMediaManager", () => $23859655abfc5f5c$export$45c5b9bfba2f6304);
$parcel$export(module.exports, "DailyMediaManager", () => $1c088932741d88e6$export$c95c65abc5f47125);
$parcel$export(module.exports, "WebSocketTransport", () => $bee70417e8ead9ed$export$de21836fc42c6f9c);
$parcel$export(module.exports, "ProtobufFrameSerializer", () => $49316c2028553492$export$4b2026f8e11b148a);
$parcel$export(module.exports, "TwilioSerializer", () => $36ab1bf4324e4b8b$export$44a8a077420336af);
// export * from "./realTimeWebSocketTransport";
// export * from "../../../lib/wavtools/dist/index.d.ts";
/**
 * Raw wav audio file contents
 * @typedef {Object} WavPackerAudioType
 * @property {Blob} blob
 * @property {string} url
 * @property {number} channelCount
 * @property {number} sampleRate
 * @property {number} duration
 */ /**
 * Utility class for assembling PCM16 "audio/wav" data
 * @class
 */ class $a61750b8fbee4dae$export$13afda237b1c9846 {
    /**
   * Converts Float32Array of amplitude data to ArrayBuffer in Int16Array format
   * @param {Float32Array} float32Array
   * @returns {ArrayBuffer}
   */ static floatTo16BitPCM(float32Array) {
        const buffer = new ArrayBuffer(float32Array.length * 2);
        const view = new DataView(buffer);
        let offset = 0;
        for(let i = 0; i < float32Array.length; i++, offset += 2){
            let s = Math.max(-1, Math.min(1, float32Array[i]));
            view.setInt16(offset, s < 0 ? s * 0x8000 : s * 0x7fff, true);
        }
        return buffer;
    }
    /**
   * Concatenates two ArrayBuffers
   * @param {ArrayBuffer} leftBuffer
   * @param {ArrayBuffer} rightBuffer
   * @returns {ArrayBuffer}
   */ static mergeBuffers(leftBuffer, rightBuffer) {
        const tmpArray = new Uint8Array(leftBuffer.byteLength + rightBuffer.byteLength);
        tmpArray.set(new Uint8Array(leftBuffer), 0);
        tmpArray.set(new Uint8Array(rightBuffer), leftBuffer.byteLength);
        return tmpArray.buffer;
    }
    /**
   * Packs data into an Int16 format
   * @private
   * @param {number} size 0 = 1x Int16, 1 = 2x Int16
   * @param {number} arg value to pack
   * @returns
   */ _packData(size, arg) {
        return [
            new Uint8Array([
                arg,
                arg >> 8
            ]),
            new Uint8Array([
                arg,
                arg >> 8,
                arg >> 16,
                arg >> 24
            ])
        ][size];
    }
    /**
   * Packs audio into "audio/wav" Blob
   * @param {number} sampleRate
   * @param {{bitsPerSample: number, channels: Array<Float32Array>, data: Int16Array}} audio
   * @returns {WavPackerAudioType}
   */ pack(sampleRate, audio) {
        if (!audio?.bitsPerSample) throw new Error(`Missing "bitsPerSample"`);
        else if (!audio?.channels) throw new Error(`Missing "channels"`);
        else if (!audio?.data) throw new Error(`Missing "data"`);
        const { bitsPerSample: bitsPerSample, channels: channels, data: data } = audio;
        const output = [
            // Header
            'RIFF',
            this._packData(1, 52),
            'WAVE',
            // chunk 1
            'fmt ',
            this._packData(1, 16),
            this._packData(0, 1),
            this._packData(0, channels.length),
            this._packData(1, sampleRate),
            this._packData(1, sampleRate * channels.length * bitsPerSample / 8),
            this._packData(0, channels.length * bitsPerSample / 8),
            this._packData(0, bitsPerSample),
            // chunk 2
            'data',
            this._packData(1, channels[0].length * channels.length * bitsPerSample / 8),
            data
        ];
        const blob = new Blob(output, {
            type: 'audio/mpeg'
        });
        const url = URL.createObjectURL(blob);
        return {
            blob: blob,
            url: url,
            channelCount: channels.length,
            sampleRate: sampleRate,
            duration: data.byteLength / (channels.length * sampleRate * 2)
        };
    }
}
globalThis.WavPacker = $a61750b8fbee4dae$export$13afda237b1c9846;


/**
 * Constants for help with visualization
 * Helps map frequency ranges from Fast Fourier Transform
 * to human-interpretable ranges, notably music ranges and
 * human vocal ranges.
 */ // Eighth octave frequencies
const $e10a9de47f58e137$var$octave8Frequencies = [
    4186.01,
    4434.92,
    4698.63,
    4978.03,
    5274.04,
    5587.65,
    5919.91,
    6271.93,
    6644.88,
    7040.0,
    7458.62,
    7902.13
];
// Labels for each of the above frequencies
const $e10a9de47f58e137$var$octave8FrequencyLabels = [
    'C',
    'C#',
    'D',
    'D#',
    'E',
    'F',
    'F#',
    'G',
    'G#',
    'A',
    'A#',
    'B'
];
const $e10a9de47f58e137$export$776c63898ae5b636 = [];
const $e10a9de47f58e137$export$facd167cc27ea9b0 = [];
for(let i = 1; i <= 8; i++)for(let f = 0; f < $e10a9de47f58e137$var$octave8Frequencies.length; f++){
    const freq = $e10a9de47f58e137$var$octave8Frequencies[f];
    $e10a9de47f58e137$export$776c63898ae5b636.push(freq / Math.pow(2, 8 - i));
    $e10a9de47f58e137$export$facd167cc27ea9b0.push($e10a9de47f58e137$var$octave8FrequencyLabels[f] + i);
}
/**
 * Subset of the note frequencies between 32 and 2000 Hz
 * 6 octave range: C1 to B6
 */ const $e10a9de47f58e137$var$voiceFrequencyRange = [
    32.0,
    2000.0
];
const $e10a9de47f58e137$export$dbc1581ed2cfa183 = $e10a9de47f58e137$export$776c63898ae5b636.filter((_, i)=>{
    return $e10a9de47f58e137$export$776c63898ae5b636[i] > $e10a9de47f58e137$var$voiceFrequencyRange[0] && $e10a9de47f58e137$export$776c63898ae5b636[i] < $e10a9de47f58e137$var$voiceFrequencyRange[1];
});
const $e10a9de47f58e137$export$30a6f2881311088f = $e10a9de47f58e137$export$facd167cc27ea9b0.filter((_, i)=>{
    return $e10a9de47f58e137$export$776c63898ae5b636[i] > $e10a9de47f58e137$var$voiceFrequencyRange[0] && $e10a9de47f58e137$export$776c63898ae5b636[i] < $e10a9de47f58e137$var$voiceFrequencyRange[1];
});


class $5853841ab58516d4$export$2c3136da0bf130f9 {
    /**
   * Retrieves frequency domain data from an AnalyserNode adjusted to a decibel range
   * returns human-readable formatting and labels
   * @param {AnalyserNode} analyser
   * @param {number} sampleRate
   * @param {Float32Array} [fftResult]
   * @param {"frequency"|"music"|"voice"} [analysisType]
   * @param {number} [minDecibels] default -100
   * @param {number} [maxDecibels] default -30
   * @returns {AudioAnalysisOutputType}
   */ static getFrequencies(analyser, sampleRate, fftResult, analysisType = 'frequency', minDecibels = -100, maxDecibels = -30) {
        if (!fftResult) {
            fftResult = new Float32Array(analyser.frequencyBinCount);
            analyser.getFloatFrequencyData(fftResult);
        }
        const nyquistFrequency = sampleRate / 2;
        const frequencyStep = 1 / fftResult.length * nyquistFrequency;
        let outputValues;
        let frequencies;
        let labels;
        if (analysisType === 'music' || analysisType === 'voice') {
            const useFrequencies = analysisType === 'voice' ? (0, $e10a9de47f58e137$export$dbc1581ed2cfa183) : (0, $e10a9de47f58e137$export$776c63898ae5b636);
            const aggregateOutput = Array(useFrequencies.length).fill(minDecibels);
            for(let i = 0; i < fftResult.length; i++){
                const frequency = i * frequencyStep;
                const amplitude = fftResult[i];
                for(let n = useFrequencies.length - 1; n >= 0; n--)if (frequency > useFrequencies[n]) {
                    aggregateOutput[n] = Math.max(aggregateOutput[n], amplitude);
                    break;
                }
            }
            outputValues = aggregateOutput;
            frequencies = analysisType === 'voice' ? (0, $e10a9de47f58e137$export$dbc1581ed2cfa183) : (0, $e10a9de47f58e137$export$776c63898ae5b636);
            labels = analysisType === 'voice' ? (0, $e10a9de47f58e137$export$30a6f2881311088f) : (0, $e10a9de47f58e137$export$facd167cc27ea9b0);
        } else {
            outputValues = Array.from(fftResult);
            frequencies = outputValues.map((_, i)=>frequencyStep * i);
            labels = frequencies.map((f)=>`${f.toFixed(2)} Hz`);
        }
        // We normalize to {0, 1}
        const normalizedOutput = outputValues.map((v)=>{
            return Math.max(0, Math.min((v - minDecibels) / (maxDecibels - minDecibels), 1));
        });
        const values = new Float32Array(normalizedOutput);
        return {
            values: values,
            frequencies: frequencies,
            labels: labels
        };
    }
    /**
   * Creates a new AudioAnalysis instance for an HTMLAudioElement
   * @param {HTMLAudioElement} audioElement
   * @param {AudioBuffer|null} [audioBuffer] If provided, will cache all frequency domain data from the buffer
   * @returns {AudioAnalysis}
   */ constructor(audioElement, audioBuffer = null){
        this.fftResults = [];
        if (audioBuffer) {
            /**
       * Modified from
       * https://stackoverflow.com/questions/75063715/using-the-web-audio-api-to-analyze-a-song-without-playing
       *
       * We do this to populate FFT values for the audio if provided an `audioBuffer`
       * The reason to do this is that Safari fails when using `createMediaElementSource`
       * This has a non-zero RAM cost so we only opt-in to run it on Safari, Chrome is better
       */ const { length: length, sampleRate: sampleRate } = audioBuffer;
            const offlineAudioContext = new OfflineAudioContext({
                length: length,
                sampleRate: sampleRate
            });
            const source = offlineAudioContext.createBufferSource();
            source.buffer = audioBuffer;
            const analyser = offlineAudioContext.createAnalyser();
            analyser.fftSize = 8192;
            analyser.smoothingTimeConstant = 0.1;
            source.connect(analyser);
            // limit is :: 128 / sampleRate;
            // but we just want 60fps - cuts ~1s from 6MB to 1MB of RAM
            const renderQuantumInSeconds = 1 / 60;
            const durationInSeconds = length / sampleRate;
            const analyze = (index)=>{
                const suspendTime = renderQuantumInSeconds * index;
                if (suspendTime < durationInSeconds) offlineAudioContext.suspend(suspendTime).then(()=>{
                    const fftResult = new Float32Array(analyser.frequencyBinCount);
                    analyser.getFloatFrequencyData(fftResult);
                    this.fftResults.push(fftResult);
                    analyze(index + 1);
                });
                if (index === 1) offlineAudioContext.startRendering();
                else offlineAudioContext.resume();
            };
            source.start(0);
            analyze(1);
            this.audio = audioElement;
            this.context = offlineAudioContext;
            this.analyser = analyser;
            this.sampleRate = sampleRate;
            this.audioBuffer = audioBuffer;
        } else {
            const audioContext = new AudioContext();
            const track = audioContext.createMediaElementSource(audioElement);
            const analyser = audioContext.createAnalyser();
            analyser.fftSize = 8192;
            analyser.smoothingTimeConstant = 0.1;
            track.connect(analyser);
            analyser.connect(audioContext.destination);
            this.audio = audioElement;
            this.context = audioContext;
            this.analyser = analyser;
            this.sampleRate = this.context.sampleRate;
            this.audioBuffer = null;
        }
    }
    /**
   * Gets the current frequency domain data from the playing audio track
   * @param {"frequency"|"music"|"voice"} [analysisType]
   * @param {number} [minDecibels] default -100
   * @param {number} [maxDecibels] default -30
   * @returns {AudioAnalysisOutputType}
   */ getFrequencies(analysisType = 'frequency', minDecibels = -100, maxDecibels = -30) {
        let fftResult = null;
        if (this.audioBuffer && this.fftResults.length) {
            const pct = this.audio.currentTime / this.audio.duration;
            const index = Math.min(pct * this.fftResults.length | 0, this.fftResults.length - 1);
            fftResult = this.fftResults[index];
        }
        return $5853841ab58516d4$export$2c3136da0bf130f9.getFrequencies(this.analyser, this.sampleRate, fftResult, analysisType, minDecibels, maxDecibels);
    }
    /**
   * Resume the internal AudioContext if it was suspended due to the lack of
   * user interaction when the AudioAnalysis was instantiated.
   * @returns {Promise<true>}
   */ async resumeIfSuspended() {
        if (this.context.state === 'suspended') await this.context.resume();
        return true;
    }
}
globalThis.AudioAnalysis = $5853841ab58516d4$export$2c3136da0bf130f9;


const $d6d3743ef65c7519$export$50b76700e2b15e9 = `
class StreamProcessor extends AudioWorkletProcessor {
  constructor() {
    super();
    this.hasStarted = false;
    this.hasInterrupted = false;
    this.outputBuffers = [];
    this.bufferLength = 128;
    this.write = { buffer: new Float32Array(this.bufferLength), trackId: null };
    this.writeOffset = 0;
    this.trackSampleOffsets = {};
    this.port.onmessage = (event) => {
      if (event.data) {
        const payload = event.data;
        if (payload.event === 'write') {
          const int16Array = payload.buffer;
          const float32Array = new Float32Array(int16Array.length);
          for (let i = 0; i < int16Array.length; i++) {
            float32Array[i] = int16Array[i] / 0x8000; // Convert Int16 to Float32
          }
          this.writeData(float32Array, payload.trackId);
        } else if (
          payload.event === 'offset' ||
          payload.event === 'interrupt'
        ) {
          const requestId = payload.requestId;
          const trackId = this.write.trackId;
          const offset = this.trackSampleOffsets[trackId] || 0;
          this.port.postMessage({
            event: 'offset',
            requestId,
            trackId,
            offset,
          });
          if (payload.event === 'interrupt') {
            this.hasInterrupted = true;
          }
        } else {
          throw new Error(\`Unhandled event "\${payload.event}"\`);
        }
      }
    };
  }

  writeData(float32Array, trackId = null) {
    let { buffer } = this.write;
    let offset = this.writeOffset;
    for (let i = 0; i < float32Array.length; i++) {
      buffer[offset++] = float32Array[i];
      if (offset >= buffer.length) {
        this.outputBuffers.push(this.write);
        this.write = { buffer: new Float32Array(this.bufferLength), trackId };
        buffer = this.write.buffer;
        offset = 0;
      }
    }
    this.writeOffset = offset;
    return true;
  }

  process(inputs, outputs, parameters) {
    const output = outputs[0];
    const outputChannelData = output[0];
    const outputBuffers = this.outputBuffers;
    if (this.hasInterrupted) {
      this.port.postMessage({ event: 'stop' });
      return false;
    } else if (outputBuffers.length) {
      this.hasStarted = true;
      const { buffer, trackId } = outputBuffers.shift();
      for (let i = 0; i < outputChannelData.length; i++) {
        outputChannelData[i] = buffer[i] || 0;
      }
      if (trackId) {
        this.trackSampleOffsets[trackId] =
          this.trackSampleOffsets[trackId] || 0;
        this.trackSampleOffsets[trackId] += buffer.length;
      }
      return true;
    } else if (this.hasStarted) {
      this.port.postMessage({ event: 'stop' });
      return false;
    } else {
      return true;
    }
  }
}

registerProcessor('stream_processor', StreamProcessor);
`;
const $d6d3743ef65c7519$var$script = new Blob([
    $d6d3743ef65c7519$export$50b76700e2b15e9
], {
    type: 'application/javascript'
});
const $d6d3743ef65c7519$var$src = URL.createObjectURL($d6d3743ef65c7519$var$script);
const $d6d3743ef65c7519$export$bfa8c596114d74df = $d6d3743ef65c7519$var$src;



class $1e7ce9484a3c4077$export$9698d62c78b8f366 {
    /**
   * Creates a new WavStreamPlayer instance
   * @param {{sampleRate?: number}} options
   * @returns {WavStreamPlayer}
   */ constructor({ sampleRate: sampleRate = 44100 } = {}){
        this.scriptSrc = (0, $d6d3743ef65c7519$export$bfa8c596114d74df);
        this.sampleRate = sampleRate;
        this.context = null;
        this.stream = null;
        this.analyser = null;
        this.trackSampleOffsets = {};
        this.interruptedTrackIds = {};
    }
    /**
   * Connects the audio context and enables output to speakers
   * @returns {Promise<true>}
   */ async connect() {
        this.context = new AudioContext({
            sampleRate: this.sampleRate
        });
        if (this._speakerID) this.context.setSinkId(this._speakerID);
        if (this.context.state === "suspended") await this.context.resume();
        try {
            await this.context.audioWorklet.addModule(this.scriptSrc);
        } catch (e) {
            console.error(e);
            throw new Error(`Could not add audioWorklet module: ${this.scriptSrc}`);
        }
        const analyser = this.context.createAnalyser();
        analyser.fftSize = 8192;
        analyser.smoothingTimeConstant = 0.1;
        this.analyser = analyser;
        return true;
    }
    /**
   * Gets the current frequency domain data from the playing track
   * @param {"frequency"|"music"|"voice"} [analysisType]
   * @param {number} [minDecibels] default -100
   * @param {number} [maxDecibels] default -30
   * @returns {import('./analysis/audio_analysis.js').AudioAnalysisOutputType}
   */ getFrequencies(analysisType = "frequency", minDecibels = -100, maxDecibels = -30) {
        if (!this.analyser) throw new Error("Not connected, please call .connect() first");
        return (0, $5853841ab58516d4$export$2c3136da0bf130f9).getFrequencies(this.analyser, this.sampleRate, null, analysisType, minDecibels, maxDecibels);
    }
    /**
   * @param {string} speaker deviceId
   */ async updateSpeaker(speaker) {
        const _prevSpeaker = this._speakerID;
        this._speakerID = speaker;
        if (this.context) try {
            if (speaker === "default") await this.context.setSinkId();
            else await this.context.setSinkId(speaker);
        } catch (e) {
            console.error(`Could not set sinkId to ${speaker}: ${e}`);
            this._speakerID = _prevSpeaker;
        }
    }
    /**
   * Starts audio streaming
   * @private
   * @returns {Promise<true>}
   */ _start() {
        const streamNode = new AudioWorkletNode(this.context, "stream_processor");
        streamNode.connect(this.context.destination);
        streamNode.port.onmessage = (e)=>{
            const { event: event } = e.data;
            if (event === "stop") {
                streamNode.disconnect();
                this.stream = null;
            } else if (event === "offset") {
                const { requestId: requestId, trackId: trackId, offset: offset } = e.data;
                const currentTime = offset / this.sampleRate;
                this.trackSampleOffsets[requestId] = {
                    trackId: trackId,
                    offset: offset,
                    currentTime: currentTime
                };
            }
        };
        this.analyser.disconnect();
        streamNode.connect(this.analyser);
        this.stream = streamNode;
        return true;
    }
    /**
   * Adds 16BitPCM data to the currently playing audio stream
   * You can add chunks beyond the current play point and they will be queued for play
   * @param {ArrayBuffer|Int16Array} arrayBuffer
   * @param {string} [trackId]
   * @returns {Int16Array}
   */ add16BitPCM(arrayBuffer, trackId = "default") {
        if (typeof trackId !== "string") throw new Error(`trackId must be a string`);
        else if (this.interruptedTrackIds[trackId]) return;
        if (!this.stream) this._start();
        let buffer;
        if (arrayBuffer instanceof Int16Array) buffer = arrayBuffer;
        else if (arrayBuffer instanceof ArrayBuffer) buffer = new Int16Array(arrayBuffer);
        else throw new Error(`argument must be Int16Array or ArrayBuffer`);
        this.stream.port.postMessage({
            event: "write",
            buffer: buffer,
            trackId: trackId
        });
        return buffer;
    }
    /**
   * Gets the offset (sample count) of the currently playing stream
   * @param {boolean} [interrupt]
   * @returns {{trackId: string|null, offset: number, currentTime: number}}
   */ async getTrackSampleOffset(interrupt = false) {
        if (!this.stream) return null;
        const requestId = crypto.randomUUID();
        this.stream.port.postMessage({
            event: interrupt ? "interrupt" : "offset",
            requestId: requestId
        });
        let trackSampleOffset;
        while(!trackSampleOffset){
            trackSampleOffset = this.trackSampleOffsets[requestId];
            await new Promise((r)=>setTimeout(()=>r(), 1));
        }
        const { trackId: trackId } = trackSampleOffset;
        if (interrupt && trackId) this.interruptedTrackIds[trackId] = true;
        return trackSampleOffset;
    }
    /**
   * Strips the current stream and returns the sample offset of the audio
   * @param {boolean} [interrupt]
   * @returns {{trackId: string|null, offset: number, currentTime: number}}
   */ async interrupt() {
        return this.getTrackSampleOffset(true);
    }
}
globalThis.WavStreamPlayer = $1e7ce9484a3c4077$export$9698d62c78b8f366;


const $2cf6a2d8a6d031bc$var$AudioProcessorWorklet = `
class AudioProcessor extends AudioWorkletProcessor {

  constructor() {
    super();
    this.port.onmessage = this.receive.bind(this);
    this.initialize();
  }

  initialize() {
    this.foundAudio = false;
    this.recording = false;
    this.chunks = [];
  }

  /**
   * Concatenates sampled chunks into channels
   * Format is chunk[Left[], Right[]]
   */
  readChannelData(chunks, channel = -1, maxChannels = 9) {
    let channelLimit;
    if (channel !== -1) {
      if (chunks[0] && chunks[0].length - 1 < channel) {
        throw new Error(
          \`Channel \${channel} out of range: max \${chunks[0].length}\`
        );
      }
      channelLimit = channel + 1;
    } else {
      channel = 0;
      channelLimit = Math.min(chunks[0] ? chunks[0].length : 1, maxChannels);
    }
    const channels = [];
    for (let n = channel; n < channelLimit; n++) {
      const length = chunks.reduce((sum, chunk) => {
        return sum + chunk[n].length;
      }, 0);
      const buffers = chunks.map((chunk) => chunk[n]);
      const result = new Float32Array(length);
      let offset = 0;
      for (let i = 0; i < buffers.length; i++) {
        result.set(buffers[i], offset);
        offset += buffers[i].length;
      }
      channels[n] = result;
    }
    return channels;
  }

  /**
   * Combines parallel audio data into correct format,
   * channels[Left[], Right[]] to float32Array[LRLRLRLR...]
   */
  formatAudioData(channels) {
    if (channels.length === 1) {
      // Simple case is only one channel
      const float32Array = channels[0].slice();
      const meanValues = channels[0].slice();
      return { float32Array, meanValues };
    } else {
      const float32Array = new Float32Array(
        channels[0].length * channels.length
      );
      const meanValues = new Float32Array(channels[0].length);
      for (let i = 0; i < channels[0].length; i++) {
        const offset = i * channels.length;
        let meanValue = 0;
        for (let n = 0; n < channels.length; n++) {
          float32Array[offset + n] = channels[n][i];
          meanValue += channels[n][i];
        }
        meanValues[i] = meanValue / channels.length;
      }
      return { float32Array, meanValues };
    }
  }

  /**
   * Converts 32-bit float data to 16-bit integers
   */
  floatTo16BitPCM(float32Array) {
    const buffer = new ArrayBuffer(float32Array.length * 2);
    const view = new DataView(buffer);
    let offset = 0;
    for (let i = 0; i < float32Array.length; i++, offset += 2) {
      let s = Math.max(-1, Math.min(1, float32Array[i]));
      view.setInt16(offset, s < 0 ? s * 0x8000 : s * 0x7fff, true);
    }
    return buffer;
  }

  /**
   * Retrieves the most recent amplitude values from the audio stream
   * @param {number} channel
   */
  getValues(channel = -1) {
    const channels = this.readChannelData(this.chunks, channel);
    const { meanValues } = this.formatAudioData(channels);
    return { meanValues, channels };
  }

  /**
   * Exports chunks as an audio/wav file
   */
  export() {
    const channels = this.readChannelData(this.chunks);
    const { float32Array, meanValues } = this.formatAudioData(channels);
    const audioData = this.floatTo16BitPCM(float32Array);
    return {
      meanValues: meanValues,
      audio: {
        bitsPerSample: 16,
        channels: channels,
        data: audioData,
      },
    };
  }

  receive(e) {
    const { event, id } = e.data;
    let receiptData = {};
    switch (event) {
      case 'start':
        this.recording = true;
        break;
      case 'stop':
        this.recording = false;
        break;
      case 'clear':
        this.initialize();
        break;
      case 'export':
        receiptData = this.export();
        break;
      case 'read':
        receiptData = this.getValues();
        break;
      default:
        break;
    }
    // Always send back receipt
    this.port.postMessage({ event: 'receipt', id, data: receiptData });
  }

  sendChunk(chunk) {
    const channels = this.readChannelData([chunk]);
    const { float32Array, meanValues } = this.formatAudioData(channels);
    const rawAudioData = this.floatTo16BitPCM(float32Array);
    const monoAudioData = this.floatTo16BitPCM(meanValues);
    this.port.postMessage({
      event: 'chunk',
      data: {
        mono: monoAudioData,
        raw: rawAudioData,
      },
    });
  }

  process(inputList, outputList, parameters) {
    // Copy input to output (e.g. speakers)
    // Note that this creates choppy sounds with Mac products
    const sourceLimit = Math.min(inputList.length, outputList.length);
    for (let inputNum = 0; inputNum < sourceLimit; inputNum++) {
      const input = inputList[inputNum];
      const output = outputList[inputNum];
      const channelCount = Math.min(input.length, output.length);
      for (let channelNum = 0; channelNum < channelCount; channelNum++) {
        input[channelNum].forEach((sample, i) => {
          output[channelNum][i] = sample;
        });
      }
    }
    const inputs = inputList[0];
    // There's latency at the beginning of a stream before recording starts
    // Make sure we actually receive audio data before we start storing chunks
    let sliceIndex = 0;
    if (!this.foundAudio) {
      for (const channel of inputs) {
        sliceIndex = 0; // reset for each channel
        if (this.foundAudio) {
          break;
        }
        if (channel) {
          for (const value of channel) {
            if (value !== 0) {
              // find only one non-zero entry in any channel
              this.foundAudio = true;
              break;
            } else {
              sliceIndex++;
            }
          }
        }
      }
    }
    if (inputs && inputs[0] && this.foundAudio && this.recording) {
      // We need to copy the TypedArray, because the \`process\`
      // internals will reuse the same buffer to hold each input
      const chunk = inputs.map((input) => input.slice(sliceIndex));
      this.chunks.push(chunk);
      this.sendChunk(chunk);
    }
    return true;
  }
}

registerProcessor('audio_processor', AudioProcessor);
`;
const $2cf6a2d8a6d031bc$var$script = new Blob([
    $2cf6a2d8a6d031bc$var$AudioProcessorWorklet
], {
    type: 'application/javascript'
});
const $2cf6a2d8a6d031bc$var$src = URL.createObjectURL($2cf6a2d8a6d031bc$var$script);
const $2cf6a2d8a6d031bc$export$1f65f50a8cbff43c = $2cf6a2d8a6d031bc$var$src;




class $0d471c38435bdab6$export$439b217ca659a877 {
    /**
   * Create a new WavRecorder instance
   * @param {{sampleRate?: number, outputToSpeakers?: boolean, debug?: boolean}} [options]
   * @returns {WavRecorder}
   */ constructor({ sampleRate: sampleRate = 44100, outputToSpeakers: outputToSpeakers = false, debug: debug = false } = {}){
        // Script source
        this.scriptSrc = (0, $2cf6a2d8a6d031bc$export$1f65f50a8cbff43c);
        // Config
        this.sampleRate = sampleRate;
        this.outputToSpeakers = outputToSpeakers;
        this.debug = !!debug;
        this._deviceChangeCallback = null;
        this._devices = [];
        this.deviceSelection = null;
        // State variables
        this.stream = null;
        this.processor = null;
        this.source = null;
        this.node = null;
        this.recording = false;
        // Event handling with AudioWorklet
        this._lastEventId = 0;
        this.eventReceipts = {};
        this.eventTimeout = 5000;
        // Process chunks of audio
        this._chunkProcessor = ()=>{};
        this._chunkProcessorSize = void 0;
        this._chunkProcessorBuffer = {
            raw: new ArrayBuffer(0),
            mono: new ArrayBuffer(0)
        };
    }
    /**
   * Decodes audio data from multiple formats to a Blob, url, Float32Array and AudioBuffer
   * @param {Blob|Float32Array|Int16Array|ArrayBuffer|number[]} audioData
   * @param {number} sampleRate
   * @param {number} fromSampleRate
   * @returns {Promise<DecodedAudioType>}
   */ static async decode(audioData, sampleRate = 44100, fromSampleRate = -1) {
        const context = new AudioContext({
            sampleRate: sampleRate
        });
        let arrayBuffer;
        let blob;
        if (audioData instanceof Blob) {
            if (fromSampleRate !== -1) throw new Error(`Can not specify "fromSampleRate" when reading from Blob`);
            blob = audioData;
            arrayBuffer = await blob.arrayBuffer();
        } else if (audioData instanceof ArrayBuffer) {
            if (fromSampleRate !== -1) throw new Error(`Can not specify "fromSampleRate" when reading from ArrayBuffer`);
            arrayBuffer = audioData;
            blob = new Blob([
                arrayBuffer
            ], {
                type: 'audio/wav'
            });
        } else {
            let float32Array;
            let data;
            if (audioData instanceof Int16Array) {
                data = audioData;
                float32Array = new Float32Array(audioData.length);
                for(let i = 0; i < audioData.length; i++)float32Array[i] = audioData[i] / 0x8000;
            } else if (audioData instanceof Float32Array) float32Array = audioData;
            else if (audioData instanceof Array) float32Array = new Float32Array(audioData);
            else throw new Error(`"audioData" must be one of: Blob, Float32Arrray, Int16Array, ArrayBuffer, Array<number>`);
            if (fromSampleRate === -1) throw new Error(`Must specify "fromSampleRate" when reading from Float32Array, In16Array or Array`);
            else if (fromSampleRate < 3000) throw new Error(`Minimum "fromSampleRate" is 3000 (3kHz)`);
            if (!data) data = (0, $a61750b8fbee4dae$export$13afda237b1c9846).floatTo16BitPCM(float32Array);
            const audio = {
                bitsPerSample: 16,
                channels: [
                    float32Array
                ],
                data: data
            };
            const packer = new (0, $a61750b8fbee4dae$export$13afda237b1c9846)();
            const result = packer.pack(fromSampleRate, audio);
            blob = result.blob;
            arrayBuffer = await blob.arrayBuffer();
        }
        const audioBuffer = await context.decodeAudioData(arrayBuffer);
        const values = audioBuffer.getChannelData(0);
        const url = URL.createObjectURL(blob);
        return {
            blob: blob,
            url: url,
            values: values,
            audioBuffer: audioBuffer
        };
    }
    /**
   * Logs data in debug mode
   * @param {...any} arguments
   * @returns {true}
   */ log() {
        if (this.debug) this.log(...arguments);
        return true;
    }
    /**
   * Retrieves the current sampleRate for the recorder
   * @returns {number}
   */ getSampleRate() {
        return this.sampleRate;
    }
    /**
   * Retrieves the current status of the recording
   * @returns {"ended"|"paused"|"recording"}
   */ getStatus() {
        if (!this.processor) return 'ended';
        else if (!this.recording) return 'paused';
        else return 'recording';
    }
    /**
   * Sends an event to the AudioWorklet
   * @private
   * @param {string} name
   * @param {{[key: string]: any}} data
   * @param {AudioWorkletNode} [_processor]
   * @returns {Promise<{[key: string]: any}>}
   */ async _event(name, data = {}, _processor = null) {
        _processor = _processor || this.processor;
        if (!_processor) throw new Error('Can not send events without recording first');
        const message = {
            event: name,
            id: this._lastEventId++,
            data: data
        };
        _processor.port.postMessage(message);
        const t0 = new Date().valueOf();
        while(!this.eventReceipts[message.id]){
            if (new Date().valueOf() - t0 > this.eventTimeout) throw new Error(`Timeout waiting for "${name}" event`);
            await new Promise((res)=>setTimeout(()=>res(true), 1));
        }
        const payload = this.eventReceipts[message.id];
        delete this.eventReceipts[message.id];
        return payload;
    }
    /**
   * Sets device change callback, remove if callback provided is `null`
   * @param {(Array<MediaDeviceInfo & {default: boolean}>): void|null} callback
   * @returns {true}
   */ listenForDeviceChange(callback) {
        if (callback === null && this._deviceChangeCallback) {
            navigator.mediaDevices.removeEventListener('devicechange', this._deviceChangeCallback);
            this._deviceChangeCallback = null;
        } else if (callback !== null) {
            // Basically a debounce; we only want this called once when devices change
            // And we only want the most recent callback() to be executed
            // if a few are operating at the same time
            let lastId = 0;
            let lastDevices = [];
            const serializeDevices = (devices)=>devices.map((d)=>d.deviceId).sort().join(',');
            const cb = async ()=>{
                let id = ++lastId;
                const devices = await this.listDevices();
                if (id === lastId) {
                    if (serializeDevices(lastDevices) !== serializeDevices(devices)) {
                        lastDevices = devices;
                        callback(devices.slice());
                    }
                }
            };
            navigator.mediaDevices.addEventListener('devicechange', cb);
            cb();
            this._deviceChangeCallback = cb;
        }
        return true;
    }
    /**
   * Manually request permission to use the microphone
   * @returns {Promise<true>}
   */ async requestPermission() {
        const permissionStatus = await navigator.permissions.query({
            name: 'microphone'
        });
        if (permissionStatus.state === 'denied') window.alert('You must grant microphone access to use this feature.');
        else if (permissionStatus.state === 'prompt') try {
            const stream = await navigator.mediaDevices.getUserMedia({
                audio: true
            });
            const tracks = stream.getTracks();
            tracks.forEach((track)=>track.stop());
        } catch (e) {
            window.alert('You must grant microphone access to use this feature.');
        }
        return true;
    }
    /**
   * List all eligible devices for recording, will request permission to use microphone
   * @returns {Promise<Array<MediaDeviceInfo & {default: boolean}>>}
   */ async listDevices() {
        if (!navigator.mediaDevices || !('enumerateDevices' in navigator.mediaDevices)) throw new Error('Could not request user devices');
        await this.requestPermission();
        const devices = await navigator.mediaDevices.enumerateDevices();
        const audioDevices = devices.filter((device)=>device.kind === 'audioinput');
        return audioDevices;
    // const defaultDeviceIndex = audioDevices.findIndex(
    //   (device) => device.deviceId === 'default'
    // );
    // const deviceList = [];
    // if (defaultDeviceIndex !== -1) {
    //   let defaultDevice = audioDevices.splice(defaultDeviceIndex, 1)[0];
    //   let existingIndex = audioDevices.findIndex(
    //     (device) => device.groupId === defaultDevice.groupId
    //   );
    //   if (existingIndex !== -1) {
    //     defaultDevice = audioDevices.splice(existingIndex, 1)[0];
    //   }
    //   defaultDevice.default = true;
    //   deviceList.push(defaultDevice);
    // }
    // return deviceList.concat(audioDevices);
    }
    /**
   * Begins a recording session and requests microphone permissions if not already granted
   * Microphone recording indicator will appear on browser tab but status will be "paused"
   * @param {string} [deviceId] if no device provided, default device will be used
   * @returns {Promise<true>}
   */ async begin(deviceId) {
        if (this.processor) throw new Error(`Already connected: please call .end() to start a new session`);
        if (!navigator.mediaDevices || !('getUserMedia' in navigator.mediaDevices)) throw new Error('Could not request user media');
        deviceId = deviceId ?? this.deviceSelection?.deviceId;
        try {
            const config = {
                audio: true
            };
            if (deviceId) config.audio = {
                deviceId: {
                    exact: deviceId
                }
            };
            this.stream = await navigator.mediaDevices.getUserMedia(config);
        } catch (err) {
            throw new Error('Could not start media stream');
        }
        this.listDevices().then((devices)=>{
            deviceId = this.stream.getAudioTracks()[0].getSettings().deviceId;
            console.log('find current device', devices, deviceId, this.stream.getAudioTracks()[0].getSettings());
            this.deviceSelection = devices.find((d)=>d.deviceId === deviceId);
            console.log('current device', this.deviceSelection);
        });
        const context = new AudioContext({
            sampleRate: this.sampleRate
        });
        const source = context.createMediaStreamSource(this.stream);
        // Load and execute the module script.
        try {
            await context.audioWorklet.addModule(this.scriptSrc);
        } catch (e) {
            console.error(e);
            throw new Error(`Could not add audioWorklet module: ${this.scriptSrc}`);
        }
        const processor = new AudioWorkletNode(context, 'audio_processor');
        processor.port.onmessage = (e)=>{
            const { event: event, id: id, data: data } = e.data;
            if (event === 'receipt') this.eventReceipts[id] = data;
            else if (event === 'chunk') {
                if (this._chunkProcessorSize) {
                    const buffer = this._chunkProcessorBuffer;
                    this._chunkProcessorBuffer = {
                        raw: (0, $a61750b8fbee4dae$export$13afda237b1c9846).mergeBuffers(buffer.raw, data.raw),
                        mono: (0, $a61750b8fbee4dae$export$13afda237b1c9846).mergeBuffers(buffer.mono, data.mono)
                    };
                    if (this._chunkProcessorBuffer.mono.byteLength >= this._chunkProcessorSize) {
                        this._chunkProcessor(this._chunkProcessorBuffer);
                        this._chunkProcessorBuffer = {
                            raw: new ArrayBuffer(0),
                            mono: new ArrayBuffer(0)
                        };
                    }
                } else this._chunkProcessor(data);
            }
        };
        const node = source.connect(processor);
        const analyser = context.createAnalyser();
        analyser.fftSize = 8192;
        analyser.smoothingTimeConstant = 0.1;
        node.connect(analyser);
        if (this.outputToSpeakers) {
            // eslint-disable-next-line no-console
            console.warn("Warning: Output to speakers may affect sound quality,\nespecially due to system audio feedback preventative measures.\nuse only for debugging");
            analyser.connect(context.destination);
        }
        this.source = source;
        this.node = node;
        this.analyser = analyser;
        this.processor = processor;
        console.log('begin completed');
        return true;
    }
    /**
   * Gets the current frequency domain data from the recording track
   * @param {"frequency"|"music"|"voice"} [analysisType]
   * @param {number} [minDecibels] default -100
   * @param {number} [maxDecibels] default -30
   * @returns {import('./analysis/audio_analysis.js').AudioAnalysisOutputType}
   */ getFrequencies(analysisType = 'frequency', minDecibels = -100, maxDecibels = -30) {
        if (!this.processor) throw new Error('Session ended: please call .begin() first');
        return (0, $5853841ab58516d4$export$2c3136da0bf130f9).getFrequencies(this.analyser, this.sampleRate, null, analysisType, minDecibels, maxDecibels);
    }
    /**
   * Pauses the recording
   * Keeps microphone stream open but halts storage of audio
   * @returns {Promise<true>}
   */ async pause() {
        if (!this.processor) throw new Error('Session ended: please call .begin() first');
        else if (!this.recording) throw new Error('Already paused: please call .record() first');
        if (this._chunkProcessorBuffer.raw.byteLength) this._chunkProcessor(this._chunkProcessorBuffer);
        this.log('Pausing ...');
        await this._event('stop');
        this.recording = false;
        return true;
    }
    /**
   * Start recording stream and storing to memory from the connected audio source
   * @param {(data: { mono: Int16Array; raw: Int16Array }) => any} [chunkProcessor]
   * @param {number} [chunkSize] chunkProcessor will not be triggered until this size threshold met in mono audio
   * @returns {Promise<true>}
   */ async record(chunkProcessor = ()=>{}, chunkSize = 8192) {
        if (!this.processor) throw new Error('Session ended: please call .begin() first');
        else if (this.recording) throw new Error('Already recording: please call .pause() first');
        else if (typeof chunkProcessor !== 'function') throw new Error(`chunkProcessor must be a function`);
        this._chunkProcessor = chunkProcessor;
        this._chunkProcessorSize = chunkSize;
        this._chunkProcessorBuffer = {
            raw: new ArrayBuffer(0),
            mono: new ArrayBuffer(0)
        };
        this.log('Recording ...');
        await this._event('start');
        this.recording = true;
        return true;
    }
    /**
   * Clears the audio buffer, empties stored recording
   * @returns {Promise<true>}
   */ async clear() {
        if (!this.processor) throw new Error('Session ended: please call .begin() first');
        await this._event('clear');
        return true;
    }
    /**
   * Reads the current audio stream data
   * @returns {Promise<{meanValues: Float32Array, channels: Array<Float32Array>}>}
   */ async read() {
        if (!this.processor) throw new Error('Session ended: please call .begin() first');
        this.log('Reading ...');
        const result = await this._event('read');
        return result;
    }
    /**
   * Saves the current audio stream to a file
   * @param {boolean} [force] Force saving while still recording
   * @returns {Promise<import('./wav_packer.js').WavPackerAudioType>}
   */ async save(force = false) {
        if (!this.processor) throw new Error('Session ended: please call .begin() first');
        if (!force && this.recording) throw new Error('Currently recording: please call .pause() first, or call .save(true) to force');
        this.log('Exporting ...');
        const exportData = await this._event('export');
        const packer = new (0, $a61750b8fbee4dae$export$13afda237b1c9846)();
        const result = packer.pack(this.sampleRate, exportData.audio);
        return result;
    }
    /**
   * Ends the current recording session and saves the result
   * @returns {Promise<import('./wav_packer.js').WavPackerAudioType>}
   */ async end() {
        if (!this.processor) throw new Error('Session ended: please call .begin() first');
        const _processor = this.processor;
        this.log('Stopping ...');
        await this._event('stop');
        this.recording = false;
        const tracks = this.stream.getTracks();
        tracks.forEach((track)=>track.stop());
        this.log('Exporting ...');
        const exportData = await this._event('export', {}, _processor);
        this.processor.disconnect();
        this.source.disconnect();
        this.node.disconnect();
        this.analyser.disconnect();
        this.stream = null;
        this.processor = null;
        this.source = null;
        this.node = null;
        const packer = new (0, $a61750b8fbee4dae$export$13afda237b1c9846)();
        const result = packer.pack(this.sampleRate, exportData.audio);
        return result;
    }
    /**
   * Performs a full cleanup of WavRecorder instance
   * Stops actively listening via microphone and removes existing listeners
   * @returns {Promise<true>}
   */ async quit() {
        this.listenForDeviceChange(null);
        // we do not reset this on end so that selections persist across starts
        this.deviceSelection = null;
        if (this.processor) await this.end();
        return true;
    }
}
globalThis.WavRecorder = $0d471c38435bdab6$export$439b217ca659a877;





class $7cef7a69bdf8f84d$export$2934cf2d25c67a48 {
    /**
   * Create a new MediaStreamRecorder instance
   * @param {{sampleRate?: number, outputToSpeakers?: boolean, debug?: boolean}} [options]
   * @returns {MediaStreamRecorder}
   */ constructor({ sampleRate: sampleRate = 44100, outputToSpeakers: outputToSpeakers = false, debug: debug = false } = {}){
        // Script source
        this.scriptSrc = (0, $2cf6a2d8a6d031bc$export$1f65f50a8cbff43c);
        // Config
        this.sampleRate = sampleRate;
        this.outputToSpeakers = outputToSpeakers;
        this.debug = !!debug;
        // State variables
        this.stream = null;
        this.processor = null;
        this.source = null;
        this.node = null;
        this.recording = false;
        // Event handling with AudioWorklet
        this._lastEventId = 0;
        this.eventReceipts = {};
        this.eventTimeout = 5000;
        // Process chunks of audio
        this._chunkProcessor = ()=>{};
        this._chunkProcessorSize = void 0;
        this._chunkProcessorBuffer = {
            raw: new ArrayBuffer(0),
            mono: new ArrayBuffer(0)
        };
    }
    /**
   * Logs data in debug mode
   * @param {...any} arguments
   * @returns {true}
   */ log() {
        if (this.debug) this.log(...arguments);
        return true;
    }
    /**
   * Retrieves the current sampleRate for the recorder
   * @returns {number}
   */ getSampleRate() {
        return this.sampleRate;
    }
    /**
   * Retrieves the current status of the recording
   * @returns {"ended"|"paused"|"recording"}
   */ getStatus() {
        if (!this.processor) return "ended";
        else if (!this.recording) return "paused";
        else return "recording";
    }
    /**
   * Sends an event to the AudioWorklet
   * @private
   * @param {string} name
   * @param {{[key: string]: any}} data
   * @param {AudioWorkletNode} [_processor]
   * @returns {Promise<{[key: string]: any}>}
   */ async _event(name, data = {}, _processor = null) {
        _processor = _processor || this.processor;
        if (!_processor) throw new Error("Can not send events without recording first");
        const message = {
            event: name,
            id: this._lastEventId++,
            data: data
        };
        _processor.port.postMessage(message);
        const t0 = new Date().valueOf();
        while(!this.eventReceipts[message.id]){
            if (new Date().valueOf() - t0 > this.eventTimeout) throw new Error(`Timeout waiting for "${name}" event`);
            await new Promise((res)=>setTimeout(()=>res(true), 1));
        }
        const payload = this.eventReceipts[message.id];
        delete this.eventReceipts[message.id];
        return payload;
    }
    /**
   * Begins a recording session for the given audioTrack
   * Microphone recording indicator will appear on browser tab but status will be "paused"
   * @param {MediaStreamTrack} [audioTrack] if no device provided, default device will be used
   * @returns {Promise<true>}
   */ async begin(audioTrack) {
        if (this.processor) throw new Error(`Already connected: please call .end() to start a new session`);
        if (!audioTrack || audioTrack.kind !== "audio") throw new Error("No audio track provided");
        this.stream = new MediaStream([
            audioTrack
        ]);
        const context = new AudioContext({
            sampleRate: this.sampleRate
        });
        const source = context.createMediaStreamSource(this.stream);
        // Load and execute the module script.
        try {
            await context.audioWorklet.addModule(this.scriptSrc);
        } catch (e) {
            console.error(e);
            throw new Error(`Could not add audioWorklet module: ${this.scriptSrc}`);
        }
        const processor = new AudioWorkletNode(context, "audio_processor");
        processor.port.onmessage = (e)=>{
            const { event: event, id: id, data: data } = e.data;
            if (event === "receipt") this.eventReceipts[id] = data;
            else if (event === "chunk") {
                if (this._chunkProcessorSize) {
                    const buffer = this._chunkProcessorBuffer;
                    this._chunkProcessorBuffer = {
                        raw: (0, $a61750b8fbee4dae$export$13afda237b1c9846).mergeBuffers(buffer.raw, data.raw),
                        mono: (0, $a61750b8fbee4dae$export$13afda237b1c9846).mergeBuffers(buffer.mono, data.mono)
                    };
                    if (this._chunkProcessorBuffer.mono.byteLength >= this._chunkProcessorSize) {
                        this._chunkProcessor(this._chunkProcessorBuffer);
                        this._chunkProcessorBuffer = {
                            raw: new ArrayBuffer(0),
                            mono: new ArrayBuffer(0)
                        };
                    }
                } else this._chunkProcessor(data);
            }
        };
        const node = source.connect(processor);
        const analyser = context.createAnalyser();
        analyser.fftSize = 8192;
        analyser.smoothingTimeConstant = 0.1;
        node.connect(analyser);
        if (this.outputToSpeakers) {
            // eslint-disable-next-line no-console
            console.warn("Warning: Output to speakers may affect sound quality,\nespecially due to system audio feedback preventative measures.\nuse only for debugging");
            analyser.connect(context.destination);
        }
        this.source = source;
        this.node = node;
        this.analyser = analyser;
        this.processor = processor;
        return true;
    }
    /**
   * Gets the current frequency domain data from the recording track
   * @param {"frequency"|"music"|"voice"} [analysisType]
   * @param {number} [minDecibels] default -100
   * @param {number} [maxDecibels] default -30
   * @returns {import('./analysis/audio_analysis.js').AudioAnalysisOutputType}
   */ getFrequencies(analysisType = "frequency", minDecibels = -100, maxDecibels = -30) {
        if (!this.processor) throw new Error("Session ended: please call .begin() first");
        return (0, $5853841ab58516d4$export$2c3136da0bf130f9).getFrequencies(this.analyser, this.sampleRate, null, analysisType, minDecibels, maxDecibels);
    }
    /**
   * Pauses the recording
   * Keeps microphone stream open but halts storage of audio
   * @returns {Promise<true>}
   */ async pause() {
        if (!this.processor) throw new Error("Session ended: please call .begin() first");
        else if (!this.recording) throw new Error("Already paused: please call .record() first");
        if (this._chunkProcessorBuffer.raw.byteLength) this._chunkProcessor(this._chunkProcessorBuffer);
        this.log("Pausing ...");
        await this._event("stop");
        this.recording = false;
        return true;
    }
    /**
   * Start recording stream and storing to memory from the connected audio source
   * @param {(data: { mono: Int16Array; raw: Int16Array }) => any} [chunkProcessor]
   * @param {number} [chunkSize] chunkProcessor will not be triggered until this size threshold met in mono audio
   * @returns {Promise<true>}
   */ async record(chunkProcessor = ()=>{}, chunkSize = 8192) {
        if (!this.processor) throw new Error("Session ended: please call .begin() first");
        else if (this.recording) throw new Error("Already recording: HELLO please call .pause() first");
        else if (typeof chunkProcessor !== "function") throw new Error(`chunkProcessor must be a function`);
        this._chunkProcessor = chunkProcessor;
        this._chunkProcessorSize = chunkSize;
        this._chunkProcessorBuffer = {
            raw: new ArrayBuffer(0),
            mono: new ArrayBuffer(0)
        };
        this.log("Recording ...");
        await this._event("start");
        this.recording = true;
        return true;
    }
    /**
   * Clears the audio buffer, empties stored recording
   * @returns {Promise<true>}
   */ async clear() {
        if (!this.processor) throw new Error("Session ended: please call .begin() first");
        await this._event("clear");
        return true;
    }
    /**
   * Reads the current audio stream data
   * @returns {Promise<{meanValues: Float32Array, channels: Array<Float32Array>}>}
   */ async read() {
        if (!this.processor) throw new Error("Session ended: please call .begin() first");
        this.log("Reading ...");
        const result = await this._event("read");
        return result;
    }
    /**
   * Saves the current audio stream to a file
   * @param {boolean} [force] Force saving while still recording
   * @returns {Promise<import('./wav_packer.js').WavPackerAudioType>}
   */ async save(force = false) {
        if (!this.processor) throw new Error("Session ended: please call .begin() first");
        if (!force && this.recording) throw new Error("Currently recording: please call .pause() first, or call .save(true) to force");
        this.log("Exporting ...");
        const exportData = await this._event("export");
        const packer = new (0, $a61750b8fbee4dae$export$13afda237b1c9846)();
        const result = packer.pack(this.sampleRate, exportData.audio);
        return result;
    }
    /**
   * Ends the current recording session and saves the result
   * @returns {Promise<import('./wav_packer.js').WavPackerAudioType>}
   */ async end() {
        if (!this.processor) throw new Error("Session ended: please call .begin() first");
        const _processor = this.processor;
        this.log("Stopping ...");
        await this._event("stop");
        this.recording = false;
        this.log("Exporting ...");
        const exportData = await this._event("export", {}, _processor);
        this.processor.disconnect();
        this.source.disconnect();
        this.node.disconnect();
        this.analyser.disconnect();
        this.stream = null;
        this.processor = null;
        this.source = null;
        this.node = null;
        const packer = new (0, $a61750b8fbee4dae$export$13afda237b1c9846)();
        const result = packer.pack(this.sampleRate, exportData.audio);
        return result;
    }
    /**
   * Performs a full cleanup of WavRecorder instance
   * Stops actively listening via microphone and removes existing listeners
   * @returns {Promise<true>}
   */ async quit() {
        this.listenForDeviceChange(null);
        if (this.processor) await this.end();
        return true;
    }
}
globalThis.WavRecorder = WavRecorder;




var $23859655abfc5f5c$var$__extends = undefined && undefined.__extends || function() {
    var extendStatics = function(d, b) {
        extendStatics = Object.setPrototypeOf || ({
            __proto__: []
        }) instanceof Array && function(d, b) {
            d.__proto__ = b;
        } || function(d, b) {
            for(var p in b)if (Object.prototype.hasOwnProperty.call(b, p)) d[p] = b[p];
        };
        return extendStatics(d, b);
    };
    return function(d, b) {
        if (typeof b !== "function" && b !== null) throw new TypeError("Class extends value " + String(b) + " is not a constructor or null");
        extendStatics(d, b);
        function __() {
            this.constructor = d;
        }
        d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());
    };
}();
var $23859655abfc5f5c$var$__awaiter = undefined && undefined.__awaiter || function(thisArg, _arguments, P, generator) {
    function adopt(value) {
        return value instanceof P ? value : new P(function(resolve) {
            resolve(value);
        });
    }
    return new (P || (P = Promise))(function(resolve, reject) {
        function fulfilled(value) {
            try {
                step(generator.next(value));
            } catch (e) {
                reject(e);
            }
        }
        function rejected(value) {
            try {
                step(generator["throw"](value));
            } catch (e) {
                reject(e);
            }
        }
        function step(result) {
            result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);
        }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};
var $23859655abfc5f5c$var$__generator = undefined && undefined.__generator || function(thisArg, body) {
    var _ = {
        label: 0,
        sent: function() {
            if (t[0] & 1) throw t[1];
            return t[1];
        },
        trys: [],
        ops: []
    }, f, y, t, g = Object.create((typeof Iterator === "function" ? Iterator : Object).prototype);
    return g.next = verb(0), g["throw"] = verb(1), g["return"] = verb(2), typeof Symbol === "function" && (g[Symbol.iterator] = function() {
        return this;
    }), g;
    function verb(n) {
        return function(v) {
            return step([
                n,
                v
            ]);
        };
    }
    function step(op) {
        if (f) throw new TypeError("Generator is already executing.");
        while(g && (g = 0, op[0] && (_ = 0)), _)try {
            if (f = 1, y && (t = op[0] & 2 ? y["return"] : op[0] ? y["throw"] || ((t = y["return"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;
            if (y = 0, t) op = [
                op[0] & 2,
                t.value
            ];
            switch(op[0]){
                case 0:
                case 1:
                    t = op;
                    break;
                case 4:
                    _.label++;
                    return {
                        value: op[1],
                        done: false
                    };
                case 5:
                    _.label++;
                    y = op[1];
                    op = [
                        0
                    ];
                    continue;
                case 7:
                    op = _.ops.pop();
                    _.trys.pop();
                    continue;
                default:
                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) {
                        _ = 0;
                        continue;
                    }
                    if (op[0] === 3 && (!t || op[1] > t[0] && op[1] < t[3])) {
                        _.label = op[1];
                        break;
                    }
                    if (op[0] === 6 && _.label < t[1]) {
                        _.label = t[1];
                        t = op;
                        break;
                    }
                    if (t && _.label < t[2]) {
                        _.label = t[2];
                        _.ops.push(op);
                        break;
                    }
                    if (t[2]) _.ops.pop();
                    _.trys.pop();
                    continue;
            }
            op = body.call(thisArg, _);
        } catch (e) {
            op = [
                6,
                e
            ];
            y = 0;
        } finally{
            f = t = 0;
        }
        if (op[0] & 5) throw op[1];
        return {
            value: op[0] ? op[1] : void 0,
            done: true
        };
    }
};
var $23859655abfc5f5c$export$4a0c46dbbe2ddb67 = /** @class */ function() {
    function MediaManager() {
        this._callbacks = {};
        this._micEnabled = true;
        this._camEnabled = false;
    }
    MediaManager.prototype.setUserAudioCallback = function(userAudioCallback) {
        this._userAudioCallback = userAudioCallback;
    };
    MediaManager.prototype.setRTVIOptions = function(options, override) {
        var _a, _b, _c;
        if (override === void 0) override = false;
        if (this._options && !override) return;
        this._options = options;
        this._callbacks = (_a = options.callbacks) !== null && _a !== void 0 ? _a : {};
        this._micEnabled = (_b = options.enableMic) !== null && _b !== void 0 ? _b : true;
        this._camEnabled = (_c = options.enableCam) !== null && _c !== void 0 ? _c : false;
    };
    return MediaManager;
}();
var $23859655abfc5f5c$export$45c5b9bfba2f6304 = /** @class */ function(_super) {
    $23859655abfc5f5c$var$__extends(WavMediaManager, _super);
    function WavMediaManager(recorderChunkSize, recorderSampleRate) {
        if (recorderChunkSize === void 0) recorderChunkSize = undefined;
        if (recorderSampleRate === void 0) recorderSampleRate = 24000;
        var _this = _super.call(this) || this;
        _this._initialized = false;
        _this._recorderChunkSize = undefined;
        _this._recorderChunkSize = recorderChunkSize;
        _this._wavRecorder = new (0, $0d471c38435bdab6$export$439b217ca659a877)({
            sampleRate: recorderSampleRate
        });
        _this._wavStreamPlayer = new (0, $1e7ce9484a3c4077$export$9698d62c78b8f366)({
            sampleRate: 24000
        });
        return _this;
    }
    WavMediaManager.prototype.initialize = function() {
        return $23859655abfc5f5c$var$__awaiter(this, void 0, Promise, function() {
            return $23859655abfc5f5c$var$__generator(this, function(_a) {
                switch(_a.label){
                    case 0:
                        return [
                            4 /*yield*/ ,
                            this._wavRecorder.begin()
                        ];
                    case 1:
                        _a.sent();
                        this._wavRecorder.listenForDeviceChange(null);
                        this._wavRecorder.listenForDeviceChange(this._handleAvailableDevicesUpdated.bind(this));
                        return [
                            4 /*yield*/ ,
                            this._wavStreamPlayer.connect()
                        ];
                    case 2:
                        _a.sent();
                        this._initialized = true;
                        return [
                            2 /*return*/ 
                        ];
                }
            });
        });
    };
    WavMediaManager.prototype.connect = function() {
        return $23859655abfc5f5c$var$__awaiter(this, void 0, Promise, function() {
            var isAlreadyRecording;
            return $23859655abfc5f5c$var$__generator(this, function(_a) {
                switch(_a.label){
                    case 0:
                        if (!!this._initialized) return [
                            3 /*break*/ ,
                            2
                        ];
                        return [
                            4 /*yield*/ ,
                            this.initialize()
                        ];
                    case 1:
                        _a.sent();
                        _a.label = 2;
                    case 2:
                        isAlreadyRecording = this._wavRecorder.getStatus() == "recording";
                        if (!(this._micEnabled && !isAlreadyRecording)) return [
                            3 /*break*/ ,
                            4
                        ];
                        return [
                            4 /*yield*/ ,
                            this._startRecording()
                        ];
                    case 3:
                        _a.sent();
                        _a.label = 4;
                    case 4:
                        return [
                            2 /*return*/ 
                        ];
                }
            });
        });
    };
    WavMediaManager.prototype.disconnect = function() {
        return $23859655abfc5f5c$var$__awaiter(this, void 0, Promise, function() {
            return $23859655abfc5f5c$var$__generator(this, function(_a) {
                switch(_a.label){
                    case 0:
                        if (!this._initialized) return [
                            2 /*return*/ 
                        ];
                        return [
                            4 /*yield*/ ,
                            this._wavRecorder.end()
                        ];
                    case 1:
                        _a.sent();
                        return [
                            4 /*yield*/ ,
                            this._wavStreamPlayer.interrupt()
                        ];
                    case 2:
                        _a.sent();
                        this._initialized = false;
                        return [
                            2 /*return*/ 
                        ];
                }
            });
        });
    };
    WavMediaManager.prototype.userStartedSpeaking = function() {
        return $23859655abfc5f5c$var$__awaiter(this, void 0, Promise, function() {
            return $23859655abfc5f5c$var$__generator(this, function(_a) {
                return [
                    2 /*return*/ ,
                    this._wavStreamPlayer.interrupt()
                ];
            });
        });
    };
    WavMediaManager.prototype.bufferBotAudio = function(data, id) {
        return this._wavStreamPlayer.add16BitPCM(data, id);
    };
    WavMediaManager.prototype.getAllMics = function() {
        return this._wavRecorder.listDevices();
    };
    WavMediaManager.prototype.getAllCams = function() {
        // TODO: Video not supported yet
        return Promise.resolve([]);
    };
    WavMediaManager.prototype.getAllSpeakers = function() {
        // TODO: Implement speaker support
        return Promise.resolve([]);
    };
    WavMediaManager.prototype.updateMic = function(micId) {
        return $23859655abfc5f5c$var$__awaiter(this, void 0, Promise, function() {
            var prevMic, curMic;
            var _a, _b;
            return $23859655abfc5f5c$var$__generator(this, function(_c) {
                switch(_c.label){
                    case 0:
                        prevMic = this._wavRecorder.deviceSelection;
                        return [
                            4 /*yield*/ ,
                            this._wavRecorder.end()
                        ];
                    case 1:
                        _c.sent();
                        return [
                            4 /*yield*/ ,
                            this._wavRecorder.begin(micId)
                        ];
                    case 2:
                        _c.sent();
                        if (!this._micEnabled) return [
                            3 /*break*/ ,
                            4
                        ];
                        return [
                            4 /*yield*/ ,
                            this._startRecording()
                        ];
                    case 3:
                        _c.sent();
                        _c.label = 4;
                    case 4:
                        curMic = this._wavRecorder.deviceSelection;
                        if (curMic && prevMic && prevMic.label !== curMic.label) (_b = (_a = this._callbacks).onMicUpdated) === null || _b === void 0 || _b.call(_a, curMic);
                        return [
                            2 /*return*/ 
                        ];
                }
            });
        });
    };
    WavMediaManager.prototype.updateCam = function(camId) {
    // TODO: Video not supported yet
    };
    WavMediaManager.prototype.updateSpeaker = function(speakerId) {
    // TODO: Implement speaker support
    };
    Object.defineProperty(WavMediaManager.prototype, "selectedMic", {
        get: function() {
            var _a;
            return (_a = this._wavRecorder.deviceSelection) !== null && _a !== void 0 ? _a : {};
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(WavMediaManager.prototype, "selectedCam", {
        get: function() {
            // TODO: Video not supported yet
            return {};
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(WavMediaManager.prototype, "selectedSpeaker", {
        get: function() {
            // TODO: Implement speaker support
            return {};
        },
        enumerable: false,
        configurable: true
    });
    WavMediaManager.prototype.enableMic = function(enable) {
        return $23859655abfc5f5c$var$__awaiter(this, void 0, Promise, function() {
            var _this = this;
            return $23859655abfc5f5c$var$__generator(this, function(_a) {
                switch(_a.label){
                    case 0:
                        this._micEnabled = enable;
                        if (!this._wavRecorder.stream) return [
                            2 /*return*/ 
                        ];
                        this._wavRecorder.stream.getAudioTracks().forEach(function(track) {
                            var _a, _b;
                            track.enabled = enable;
                            if (!enable) (_b = (_a = _this._callbacks).onTrackStopped) === null || _b === void 0 || _b.call(_a, track, $23859655abfc5f5c$var$localParticipant());
                        });
                        if (!enable) return [
                            3 /*break*/ ,
                            2
                        ];
                        return [
                            4 /*yield*/ ,
                            this._startRecording()
                        ];
                    case 1:
                        _a.sent();
                        return [
                            3 /*break*/ ,
                            4
                        ];
                    case 2:
                        return [
                            4 /*yield*/ ,
                            this._wavRecorder.pause()
                        ];
                    case 3:
                        _a.sent();
                        _a.label = 4;
                    case 4:
                        return [
                            2 /*return*/ 
                        ];
                }
            });
        });
    };
    WavMediaManager.prototype.enableCam = function(enable) {
    // TODO: Video not supported yet
    };
    Object.defineProperty(WavMediaManager.prototype, "isCamEnabled", {
        get: function() {
            // TODO: Video not supported yet
            return false;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(WavMediaManager.prototype, "isMicEnabled", {
        get: function() {
            return this._micEnabled;
        },
        enumerable: false,
        configurable: true
    });
    WavMediaManager.prototype.tracks = function() {
        var _a;
        var tracks = (_a = this._wavRecorder.stream) === null || _a === void 0 ? void 0 : _a.getTracks()[0];
        return {
            local: tracks ? {
                audio: tracks
            } : {}
        };
    };
    WavMediaManager.prototype._startRecording = function() {
        return $23859655abfc5f5c$var$__awaiter(this, void 0, void 0, function() {
            var track;
            var _this = this;
            var _a, _b, _c;
            return $23859655abfc5f5c$var$__generator(this, function(_d) {
                switch(_d.label){
                    case 0:
                        return [
                            4 /*yield*/ ,
                            this._wavRecorder.record(function(data) {
                                _this._userAudioCallback(data.mono);
                            }, this._recorderChunkSize)
                        ];
                    case 1:
                        _d.sent();
                        track = (_a = this._wavRecorder.stream) === null || _a === void 0 ? void 0 : _a.getAudioTracks()[0];
                        if (track) (_c = (_b = this._callbacks).onTrackStarted) === null || _c === void 0 || _c.call(_b, track, $23859655abfc5f5c$var$localParticipant());
                        return [
                            2 /*return*/ 
                        ];
                }
            });
        });
    };
    WavMediaManager.prototype._handleAvailableDevicesUpdated = function(devices) {
        var _a, _b, _c, _d;
        (_b = (_a = this._callbacks).onAvailableCamsUpdated) === null || _b === void 0 || _b.call(_a, devices.filter(function(d) {
            return d.kind === "videoinput";
        }));
        (_d = (_c = this._callbacks).onAvailableMicsUpdated) === null || _d === void 0 || _d.call(_c, devices.filter(function(d) {
            return d.kind === "audioinput";
        }));
        // if the current device went away or we're using the default and
        // the default changed, reset the mic.
        var defaultDevice = devices.find(function(d) {
            return d.deviceId === "default";
        });
        var currentDevice = this._wavRecorder.deviceSelection;
        if (currentDevice && (!devices.some(function(d) {
            return d.deviceId === currentDevice.deviceId;
        }) || currentDevice.deviceId === "default" && currentDevice.label !== (defaultDevice === null || defaultDevice === void 0 ? void 0 : defaultDevice.label))) this.updateMic("");
    };
    return WavMediaManager;
}($23859655abfc5f5c$export$4a0c46dbbe2ddb67);
var $23859655abfc5f5c$var$localParticipant = function() {
    return {
        id: "local",
        name: "",
        local: true
    };
};





var $1c088932741d88e6$var$__extends = undefined && undefined.__extends || function() {
    var extendStatics = function(d, b) {
        extendStatics = Object.setPrototypeOf || ({
            __proto__: []
        }) instanceof Array && function(d, b) {
            d.__proto__ = b;
        } || function(d, b) {
            for(var p in b)if (Object.prototype.hasOwnProperty.call(b, p)) d[p] = b[p];
        };
        return extendStatics(d, b);
    };
    return function(d, b) {
        if (typeof b !== "function" && b !== null) throw new TypeError("Class extends value " + String(b) + " is not a constructor or null");
        extendStatics(d, b);
        function __() {
            this.constructor = d;
        }
        d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());
    };
}();
var $1c088932741d88e6$var$__awaiter = undefined && undefined.__awaiter || function(thisArg, _arguments, P, generator) {
    function adopt(value) {
        return value instanceof P ? value : new P(function(resolve) {
            resolve(value);
        });
    }
    return new (P || (P = Promise))(function(resolve, reject) {
        function fulfilled(value) {
            try {
                step(generator.next(value));
            } catch (e) {
                reject(e);
            }
        }
        function rejected(value) {
            try {
                step(generator["throw"](value));
            } catch (e) {
                reject(e);
            }
        }
        function step(result) {
            result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);
        }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};
var $1c088932741d88e6$var$__generator = undefined && undefined.__generator || function(thisArg, body) {
    var _ = {
        label: 0,
        sent: function() {
            if (t[0] & 1) throw t[1];
            return t[1];
        },
        trys: [],
        ops: []
    }, f, y, t, g = Object.create((typeof Iterator === "function" ? Iterator : Object).prototype);
    return g.next = verb(0), g["throw"] = verb(1), g["return"] = verb(2), typeof Symbol === "function" && (g[Symbol.iterator] = function() {
        return this;
    }), g;
    function verb(n) {
        return function(v) {
            return step([
                n,
                v
            ]);
        };
    }
    function step(op) {
        if (f) throw new TypeError("Generator is already executing.");
        while(g && (g = 0, op[0] && (_ = 0)), _)try {
            if (f = 1, y && (t = op[0] & 2 ? y["return"] : op[0] ? y["throw"] || ((t = y["return"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;
            if (y = 0, t) op = [
                op[0] & 2,
                t.value
            ];
            switch(op[0]){
                case 0:
                case 1:
                    t = op;
                    break;
                case 4:
                    _.label++;
                    return {
                        value: op[1],
                        done: false
                    };
                case 5:
                    _.label++;
                    y = op[1];
                    op = [
                        0
                    ];
                    continue;
                case 7:
                    op = _.ops.pop();
                    _.trys.pop();
                    continue;
                default:
                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) {
                        _ = 0;
                        continue;
                    }
                    if (op[0] === 3 && (!t || op[1] > t[0] && op[1] < t[3])) {
                        _.label = op[1];
                        break;
                    }
                    if (op[0] === 6 && _.label < t[1]) {
                        _.label = t[1];
                        t = op;
                        break;
                    }
                    if (t && _.label < t[2]) {
                        _.label = t[2];
                        _.ops.push(op);
                        break;
                    }
                    if (t[2]) _.ops.pop();
                    _.trys.pop();
                    continue;
            }
            op = body.call(thisArg, _);
        } catch (e) {
            op = [
                6,
                e
            ];
            y = 0;
        } finally{
            f = t = 0;
        }
        if (op[0] & 5) throw op[1];
        return {
            value: op[0] ? op[1] : void 0,
            done: true
        };
    }
};
var $1c088932741d88e6$export$c95c65abc5f47125 = /** @class */ function(_super) {
    $1c088932741d88e6$var$__extends(DailyMediaManager, _super);
    function DailyMediaManager(enablePlayer, enableRecording, onTrackStartedCallback, onTrackStoppedCallback, recorderChunkSize, recorderSampleRate, playerSampleRate) {
        if (enablePlayer === void 0) enablePlayer = true;
        if (enableRecording === void 0) enableRecording = true;
        if (recorderChunkSize === void 0) recorderChunkSize = undefined;
        if (recorderSampleRate === void 0) recorderSampleRate = 24000;
        if (playerSampleRate === void 0) playerSampleRate = 24000;
        var _a;
        var _this = _super.call(this) || this;
        _this._selectedCam = {};
        _this._selectedMic = {};
        _this._selectedSpeaker = {};
        _this._remoteAudioLevelInterval = null;
        _this._recorderChunkSize = undefined;
        _this._initialized = false;
        _this._connected = false;
        _this._currentAudioTrack = null;
        _this._connectResolve = null;
        _this.onTrackStartedCallback = onTrackStartedCallback;
        _this.onTrackStoppedCallback = onTrackStoppedCallback;
        _this._recorderChunkSize = recorderChunkSize;
        _this._daily = (_a = (0, ($parcel$interopDefault($fkNis$dailycodailyjs))).getCallInstance()) !== null && _a !== void 0 ? _a : (0, ($parcel$interopDefault($fkNis$dailycodailyjs))).createCallObject();
        if (enableRecording) _this._mediaStreamRecorder = new (0, $7cef7a69bdf8f84d$export$2934cf2d25c67a48)({
            sampleRate: recorderSampleRate
        });
        if (enablePlayer) _this._wavStreamPlayer = new (0, $1e7ce9484a3c4077$export$9698d62c78b8f366)({
            sampleRate: playerSampleRate
        });
        _this._daily.on("track-started", _this.handleTrackStarted.bind(_this));
        _this._daily.on("track-stopped", _this.handleTrackStopped.bind(_this));
        _this._daily.on("available-devices-updated", _this._handleAvailableDevicesUpdated.bind(_this));
        _this._daily.on("selected-devices-updated", _this._handleSelectedDevicesUpdated.bind(_this));
        _this._daily.on("local-audio-level", _this._handleLocalAudioLevel.bind(_this));
        return _this;
    }
    DailyMediaManager.prototype.initialize = function() {
        return $1c088932741d88e6$var$__awaiter(this, void 0, Promise, function() {
            var infos, devices, cams, mics, speakers;
            var _this = this;
            var _a, _b, _c, _d, _e, _f, _g, _h, _j, _k, _l, _m;
            return $1c088932741d88e6$var$__generator(this, function(_o) {
                switch(_o.label){
                    case 0:
                        if (this._initialized) {
                            console.warn("DailyMediaManager already initialized");
                            return [
                                2 /*return*/ 
                            ];
                        }
                        return [
                            4 /*yield*/ ,
                            this._daily.startCamera({
                                startVideoOff: !this._camEnabled,
                                startAudioOff: !this._micEnabled
                            })
                        ];
                    case 1:
                        infos = _o.sent();
                        return [
                            4 /*yield*/ ,
                            this._daily.enumerateDevices()
                        ];
                    case 2:
                        devices = _o.sent().devices;
                        cams = devices.filter(function(d) {
                            return d.kind === "videoinput";
                        });
                        mics = devices.filter(function(d) {
                            return d.kind === "audioinput";
                        });
                        speakers = devices.filter(function(d) {
                            return d.kind === "audiooutput";
                        });
                        (_b = (_a = this._callbacks).onAvailableCamsUpdated) === null || _b === void 0 || _b.call(_a, cams);
                        (_d = (_c = this._callbacks).onAvailableMicsUpdated) === null || _d === void 0 || _d.call(_c, mics);
                        (_f = (_e = this._callbacks).onAvailableSpeakersUpdated) === null || _f === void 0 || _f.call(_e, speakers);
                        this._selectedCam = infos.camera;
                        (_h = (_g = this._callbacks).onCamUpdated) === null || _h === void 0 || _h.call(_g, infos.camera);
                        this._selectedMic = infos.mic;
                        (_k = (_j = this._callbacks).onMicUpdated) === null || _k === void 0 || _k.call(_j, infos.mic);
                        this._selectedSpeaker = infos.speaker;
                        (_m = (_l = this._callbacks).onSpeakerUpdated) === null || _m === void 0 || _m.call(_l, infos.speaker);
                        if (!!this._daily.isLocalAudioLevelObserverRunning()) return [
                            3 /*break*/ ,
                            4
                        ];
                        return [
                            4 /*yield*/ ,
                            this._daily.startLocalAudioLevelObserver(100)
                        ];
                    case 3:
                        _o.sent();
                        _o.label = 4;
                    case 4:
                        if (!this._wavStreamPlayer) return [
                            3 /*break*/ ,
                            6
                        ];
                        return [
                            4 /*yield*/ ,
                            this._wavStreamPlayer.connect()
                        ];
                    case 5:
                        _o.sent();
                        if (!this._remoteAudioLevelInterval) this._remoteAudioLevelInterval = setInterval(function() {
                            var _a;
                            var frequencies = _this._wavStreamPlayer.getFrequencies();
                            var aveVal = 0;
                            if ((_a = frequencies.values) === null || _a === void 0 ? void 0 : _a.length) aveVal = frequencies.values.reduce(function(a, c) {
                                return a + c;
                            }, 0) / frequencies.values.length;
                            _this._handleRemoteAudioLevel(aveVal);
                        }, 100);
                        _o.label = 6;
                    case 6:
                        this._initialized = true;
                        return [
                            2 /*return*/ 
                        ];
                }
            });
        });
    };
    DailyMediaManager.prototype.connect = function() {
        return $1c088932741d88e6$var$__awaiter(this, void 0, Promise, function() {
            var _this = this;
            return $1c088932741d88e6$var$__generator(this, function(_a) {
                if (this._connected) {
                    console.warn("DailyMediaManager already connected");
                    return [
                        2 /*return*/ 
                    ];
                }
                this._connected = true;
                if (!this._initialized) return [
                    2 /*return*/ ,
                    new Promise(function(resolve) {
                        (function() {
                            return $1c088932741d88e6$var$__awaiter(_this, void 0, void 0, function() {
                                return $1c088932741d88e6$var$__generator(this, function(_a) {
                                    switch(_a.label){
                                        case 0:
                                            this._connectResolve = resolve;
                                            return [
                                                4 /*yield*/ ,
                                                this.initialize()
                                            ];
                                        case 1:
                                            _a.sent();
                                            return [
                                                2 /*return*/ 
                                            ];
                                    }
                                });
                            });
                        })();
                    })
                ];
                if (this._micEnabled) this._startRecording();
                return [
                    2 /*return*/ 
                ];
            });
        });
    };
    DailyMediaManager.prototype.disconnect = function() {
        return $1c088932741d88e6$var$__awaiter(this, void 0, Promise, function() {
            var _a, _b;
            return $1c088932741d88e6$var$__generator(this, function(_c) {
                switch(_c.label){
                    case 0:
                        if (this._remoteAudioLevelInterval) clearInterval(this._remoteAudioLevelInterval);
                        this._remoteAudioLevelInterval = null;
                        this._daily.leave();
                        this._currentAudioTrack = null;
                        return [
                            4 /*yield*/ ,
                            (_a = this._mediaStreamRecorder) === null || _a === void 0 ? void 0 : _a.end()
                        ];
                    case 1:
                        _c.sent();
                        (_b = this._wavStreamPlayer) === null || _b === void 0 || _b.interrupt();
                        this._initialized = false;
                        this._connected = false;
                        return [
                            2 /*return*/ 
                        ];
                }
            });
        });
    };
    DailyMediaManager.prototype.userStartedSpeaking = function() {
        return $1c088932741d88e6$var$__awaiter(this, void 0, Promise, function() {
            var _a;
            return $1c088932741d88e6$var$__generator(this, function(_b) {
                return [
                    2 /*return*/ ,
                    (_a = this._wavStreamPlayer) === null || _a === void 0 ? void 0 : _a.interrupt()
                ];
            });
        });
    };
    DailyMediaManager.prototype.bufferBotAudio = function(data, id) {
        var _a;
        return (_a = this._wavStreamPlayer) === null || _a === void 0 ? void 0 : _a.add16BitPCM(data, id);
    };
    DailyMediaManager.prototype.getAllMics = function() {
        return $1c088932741d88e6$var$__awaiter(this, void 0, Promise, function() {
            var devices;
            return $1c088932741d88e6$var$__generator(this, function(_a) {
                switch(_a.label){
                    case 0:
                        return [
                            4 /*yield*/ ,
                            this._daily.enumerateDevices()
                        ];
                    case 1:
                        devices = _a.sent().devices;
                        return [
                            2 /*return*/ ,
                            devices.filter(function(device) {
                                return device.kind === "audioinput";
                            })
                        ];
                }
            });
        });
    };
    DailyMediaManager.prototype.getAllCams = function() {
        return $1c088932741d88e6$var$__awaiter(this, void 0, Promise, function() {
            var devices;
            return $1c088932741d88e6$var$__generator(this, function(_a) {
                switch(_a.label){
                    case 0:
                        return [
                            4 /*yield*/ ,
                            this._daily.enumerateDevices()
                        ];
                    case 1:
                        devices = _a.sent().devices;
                        return [
                            2 /*return*/ ,
                            devices.filter(function(device) {
                                return device.kind === "videoinput";
                            })
                        ];
                }
            });
        });
    };
    DailyMediaManager.prototype.getAllSpeakers = function() {
        return $1c088932741d88e6$var$__awaiter(this, void 0, Promise, function() {
            var devices;
            return $1c088932741d88e6$var$__generator(this, function(_a) {
                switch(_a.label){
                    case 0:
                        return [
                            4 /*yield*/ ,
                            this._daily.enumerateDevices()
                        ];
                    case 1:
                        devices = _a.sent().devices;
                        return [
                            2 /*return*/ ,
                            devices.filter(function(device) {
                                return device.kind === "audiooutput";
                            })
                        ];
                }
            });
        });
    };
    DailyMediaManager.prototype.updateMic = function(micId) {
        var _this = this;
        this._daily.setInputDevicesAsync({
            audioDeviceId: micId
        }).then(function(deviceInfo) {
            _this._selectedMic = deviceInfo.mic;
        });
    };
    DailyMediaManager.prototype.updateCam = function(camId) {
        var _this = this;
        this._daily.setInputDevicesAsync({
            videoDeviceId: camId
        }).then(function(deviceInfo) {
            _this._selectedCam = deviceInfo.camera;
        });
    };
    DailyMediaManager.prototype.updateSpeaker = function(speakerId) {
        return $1c088932741d88e6$var$__awaiter(this, void 0, Promise, function() {
            var sID, speakers, defaultSpeaker_1, defaultSpeakerCp;
            var _this = this;
            var _a, _b;
            return $1c088932741d88e6$var$__generator(this, function(_c) {
                switch(_c.label){
                    case 0:
                        if (speakerId !== "default" && this._selectedSpeaker.deviceId === speakerId) return [
                            2 /*return*/ 
                        ];
                        sID = speakerId;
                        if (!(sID === "default")) return [
                            3 /*break*/ ,
                            2
                        ];
                        return [
                            4 /*yield*/ ,
                            this.getAllSpeakers()
                        ];
                    case 1:
                        speakers = _c.sent();
                        defaultSpeaker_1 = speakers.find(function(s) {
                            return s.deviceId === "default";
                        });
                        if (!defaultSpeaker_1) {
                            console.warn("No default speaker found");
                            return [
                                2 /*return*/ 
                            ];
                        }
                        speakers.splice(speakers.indexOf(defaultSpeaker_1), 1);
                        defaultSpeakerCp = speakers.find(function(s) {
                            return defaultSpeaker_1.label.includes(s.label);
                        });
                        sID = (_a = defaultSpeakerCp === null || defaultSpeakerCp === void 0 ? void 0 : defaultSpeakerCp.deviceId) !== null && _a !== void 0 ? _a : speakerId;
                        _c.label = 2;
                    case 2:
                        (_b = this._wavStreamPlayer) === null || _b === void 0 || _b.updateSpeaker(sID).then(function() {
                            var _a, _b;
                            _this._selectedSpeaker = {
                                deviceId: speakerId
                            };
                            (_b = (_a = _this._callbacks).onSpeakerUpdated) === null || _b === void 0 || _b.call(_a, _this._selectedSpeaker);
                        });
                        return [
                            2 /*return*/ 
                        ];
                }
            });
        });
    };
    Object.defineProperty(DailyMediaManager.prototype, "selectedMic", {
        get: function() {
            return this._selectedMic;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(DailyMediaManager.prototype, "selectedCam", {
        get: function() {
            return this._selectedCam;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(DailyMediaManager.prototype, "selectedSpeaker", {
        get: function() {
            return this._selectedSpeaker;
        },
        enumerable: false,
        configurable: true
    });
    DailyMediaManager.prototype.enableMic = function(enable) {
        return $1c088932741d88e6$var$__awaiter(this, void 0, Promise, function() {
            var _a;
            return $1c088932741d88e6$var$__generator(this, function(_b) {
                this._micEnabled = enable;
                if (!((_a = this._daily.participants()) === null || _a === void 0 ? void 0 : _a.local)) return [
                    2 /*return*/ 
                ];
                this._daily.setLocalAudio(enable);
                if (this._mediaStreamRecorder) {
                    if (enable) {
                        if (this._mediaStreamRecorder.getStatus() === "paused") this._startRecording();
                         // else, we'll record on the track-started event
                    } else if (this._mediaStreamRecorder.getStatus() === "recording") this._mediaStreamRecorder.pause();
                }
                return [
                    2 /*return*/ 
                ];
            });
        });
    };
    DailyMediaManager.prototype.enableCam = function(enable) {
        this._camEnabled = enable;
        this._daily.setLocalVideo(enable);
    };
    Object.defineProperty(DailyMediaManager.prototype, "isCamEnabled", {
        get: function() {
            return this._daily.localVideo();
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(DailyMediaManager.prototype, "isMicEnabled", {
        get: function() {
            return this._daily.localAudio();
        },
        enumerable: false,
        configurable: true
    });
    DailyMediaManager.prototype.tracks = function() {
        var _a, _b, _c, _d, _e, _f;
        var participants = this._daily.participants();
        return {
            local: {
                audio: (_c = (_b = (_a = participants === null || participants === void 0 ? void 0 : participants.local) === null || _a === void 0 ? void 0 : _a.tracks) === null || _b === void 0 ? void 0 : _b.audio) === null || _c === void 0 ? void 0 : _c.persistentTrack,
                video: (_f = (_e = (_d = participants === null || participants === void 0 ? void 0 : participants.local) === null || _d === void 0 ? void 0 : _d.tracks) === null || _e === void 0 ? void 0 : _e.video) === null || _f === void 0 ? void 0 : _f.persistentTrack
            }
        };
    };
    DailyMediaManager.prototype._startRecording = function() {
        var _this = this;
        if (!this._connected || !this._mediaStreamRecorder) return;
        try {
            this._mediaStreamRecorder.record(function(data) {
                _this._userAudioCallback(data.mono);
            }, this._recorderChunkSize);
        } catch (e) {
            var err = e;
            if (!err.message.includes("Already recording")) console.error("Error starting recording", e);
        }
    };
    DailyMediaManager.prototype._handleAvailableDevicesUpdated = function(event) {
        var _a, _b, _c, _d, _e, _f;
        (_b = (_a = this._callbacks).onAvailableCamsUpdated) === null || _b === void 0 || _b.call(_a, event.availableDevices.filter(function(d) {
            return d.kind === "videoinput";
        }));
        (_d = (_c = this._callbacks).onAvailableMicsUpdated) === null || _d === void 0 || _d.call(_c, event.availableDevices.filter(function(d) {
            return d.kind === "audioinput";
        }));
        (_f = (_e = this._callbacks).onAvailableSpeakersUpdated) === null || _f === void 0 || _f.call(_e, event.availableDevices.filter(function(d) {
            return d.kind === "audiooutput";
        }));
        if (this._selectedSpeaker.deviceId === "default") this.updateSpeaker("default");
    };
    DailyMediaManager.prototype._handleSelectedDevicesUpdated = function(event) {
        var _a, _b, _c, _d, _e, _f;
        if (((_a = this._selectedCam) === null || _a === void 0 ? void 0 : _a.deviceId) !== event.devices.camera) {
            this._selectedCam = event.devices.camera;
            (_c = (_b = this._callbacks).onCamUpdated) === null || _c === void 0 || _c.call(_b, event.devices.camera);
        }
        if (((_d = this._selectedMic) === null || _d === void 0 ? void 0 : _d.deviceId) !== event.devices.mic) {
            this._selectedMic = event.devices.mic;
            (_f = (_e = this._callbacks).onMicUpdated) === null || _f === void 0 || _f.call(_e, event.devices.mic);
        }
    };
    DailyMediaManager.prototype._handleLocalAudioLevel = function(ev) {
        var _a, _b;
        (_b = (_a = this._callbacks).onLocalAudioLevel) === null || _b === void 0 || _b.call(_a, ev.audioLevel);
    };
    DailyMediaManager.prototype._handleRemoteAudioLevel = function(audioLevel) {
        var _a, _b;
        (_b = (_a = this._callbacks).onRemoteAudioLevel) === null || _b === void 0 || _b.call(_a, audioLevel, $1c088932741d88e6$var$botParticipant());
    };
    DailyMediaManager.prototype.handleTrackStarted = function(event) {
        return $1c088932741d88e6$var$__awaiter(this, void 0, void 0, function() {
            var status, _a;
            var _b, _c, _d, _e;
            return $1c088932741d88e6$var$__generator(this, function(_f) {
                switch(_f.label){
                    case 0:
                        if (!((_b = event.participant) === null || _b === void 0 ? void 0 : _b.local)) return [
                            2 /*return*/ 
                        ];
                        if (!(event.track.kind === "audio")) return [
                            3 /*break*/ ,
                            10
                        ];
                        if (!this._mediaStreamRecorder) return [
                            3 /*break*/ ,
                            9
                        ];
                        status = this._mediaStreamRecorder.getStatus();
                        _a = status;
                        switch(_a){
                            case "ended":
                                return [
                                    3 /*break*/ ,
                                    1
                                ];
                            case "paused":
                                return [
                                    3 /*break*/ ,
                                    3
                                ];
                            case "recording":
                                return [
                                    3 /*break*/ ,
                                    4
                                ];
                        }
                        return [
                            3 /*break*/ ,
                            4
                        ];
                    case 1:
                        return [
                            4 /*yield*/ ,
                            this._mediaStreamRecorder.begin(event.track)
                        ];
                    case 2:
                        _f.sent();
                        if (this._connected) {
                            this._startRecording();
                            if (this._connectResolve) {
                                this._connectResolve();
                                this._connectResolve = null;
                            }
                        }
                        return [
                            3 /*break*/ ,
                            9
                        ];
                    case 3:
                        this._startRecording();
                        return [
                            3 /*break*/ ,
                            9
                        ];
                    case 4:
                        if (!(this._currentAudioTrack !== event.track)) return [
                            3 /*break*/ ,
                            7
                        ];
                        return [
                            4 /*yield*/ ,
                            this._mediaStreamRecorder.end()
                        ];
                    case 5:
                        _f.sent();
                        return [
                            4 /*yield*/ ,
                            this._mediaStreamRecorder.begin(event.track)
                        ];
                    case 6:
                        _f.sent();
                        this._startRecording();
                        return [
                            3 /*break*/ ,
                            8
                        ];
                    case 7:
                        console.warn("track-started event received for current track and already recording");
                        _f.label = 8;
                    case 8:
                        return [
                            3 /*break*/ ,
                            9
                        ];
                    case 9:
                        this._currentAudioTrack = event.track;
                        _f.label = 10;
                    case 10:
                        (_d = (_c = this._callbacks).onTrackStarted) === null || _d === void 0 || _d.call(_c, event.track, event.participant ? $1c088932741d88e6$var$dailyParticipantToParticipant(event.participant) : undefined);
                        (_e = this.onTrackStartedCallback) === null || _e === void 0 || _e.call(this, event);
                        return [
                            2 /*return*/ 
                        ];
                }
            });
        });
    };
    DailyMediaManager.prototype.handleTrackStopped = function(event) {
        var _a, _b, _c, _d;
        if (!((_a = event.participant) === null || _a === void 0 ? void 0 : _a.local)) return;
        if (event.track.kind === "audio") {
            if (this._mediaStreamRecorder && this._mediaStreamRecorder.getStatus() === "recording") this._mediaStreamRecorder.pause();
        }
        (_c = (_b = this._callbacks).onTrackStopped) === null || _c === void 0 || _c.call(_b, event.track, event.participant ? $1c088932741d88e6$var$dailyParticipantToParticipant(event.participant) : undefined);
        (_d = this.onTrackStoppedCallback) === null || _d === void 0 || _d.call(this, event);
    };
    return DailyMediaManager;
}((0, $23859655abfc5f5c$export$4a0c46dbbe2ddb67));
var $1c088932741d88e6$var$dailyParticipantToParticipant = function(p) {
    return {
        id: p.user_id,
        local: p.local,
        name: p.user_name
    };
};
var $1c088932741d88e6$var$botParticipant = function() {
    return {
        id: "bot",
        local: false,
        name: "Bot"
    };
};




var $158ad1a38fb85e0e$var$__extends = undefined && undefined.__extends || function() {
    var extendStatics = function(d, b) {
        extendStatics = Object.setPrototypeOf || ({
            __proto__: []
        }) instanceof Array && function(d, b) {
            d.__proto__ = b;
        } || function(d, b) {
            for(var p in b)if (Object.prototype.hasOwnProperty.call(b, p)) d[p] = b[p];
        };
        return extendStatics(d, b);
    };
    return function(d, b) {
        if (typeof b !== "function" && b !== null) throw new TypeError("Class extends value " + String(b) + " is not a constructor or null");
        extendStatics(d, b);
        function __() {
            this.constructor = d;
        }
        d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());
    };
}();
var $158ad1a38fb85e0e$var$__awaiter = undefined && undefined.__awaiter || function(thisArg, _arguments, P, generator) {
    function adopt(value) {
        return value instanceof P ? value : new P(function(resolve) {
            resolve(value);
        });
    }
    return new (P || (P = Promise))(function(resolve, reject) {
        function fulfilled(value) {
            try {
                step(generator.next(value));
            } catch (e) {
                reject(e);
            }
        }
        function rejected(value) {
            try {
                step(generator["throw"](value));
            } catch (e) {
                reject(e);
            }
        }
        function step(result) {
            result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);
        }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};
var $158ad1a38fb85e0e$var$__generator = undefined && undefined.__generator || function(thisArg, body) {
    var _ = {
        label: 0,
        sent: function() {
            if (t[0] & 1) throw t[1];
            return t[1];
        },
        trys: [],
        ops: []
    }, f, y, t, g = Object.create((typeof Iterator === "function" ? Iterator : Object).prototype);
    return g.next = verb(0), g["throw"] = verb(1), g["return"] = verb(2), typeof Symbol === "function" && (g[Symbol.iterator] = function() {
        return this;
    }), g;
    function verb(n) {
        return function(v) {
            return step([
                n,
                v
            ]);
        };
    }
    function step(op) {
        if (f) throw new TypeError("Generator is already executing.");
        while(g && (g = 0, op[0] && (_ = 0)), _)try {
            if (f = 1, y && (t = op[0] & 2 ? y["return"] : op[0] ? y["throw"] || ((t = y["return"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;
            if (y = 0, t) op = [
                op[0] & 2,
                t.value
            ];
            switch(op[0]){
                case 0:
                case 1:
                    t = op;
                    break;
                case 4:
                    _.label++;
                    return {
                        value: op[1],
                        done: false
                    };
                case 5:
                    _.label++;
                    y = op[1];
                    op = [
                        0
                    ];
                    continue;
                case 7:
                    op = _.ops.pop();
                    _.trys.pop();
                    continue;
                default:
                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) {
                        _ = 0;
                        continue;
                    }
                    if (op[0] === 3 && (!t || op[1] > t[0] && op[1] < t[3])) {
                        _.label = op[1];
                        break;
                    }
                    if (op[0] === 6 && _.label < t[1]) {
                        _.label = t[1];
                        t = op;
                        break;
                    }
                    if (t && _.label < t[2]) {
                        _.label = t[2];
                        _.ops.push(op);
                        break;
                    }
                    if (t[2]) _.ops.pop();
                    _.trys.pop();
                    continue;
            }
            op = body.call(thisArg, _);
        } catch (e) {
            op = [
                6,
                e
            ];
            y = 0;
        } finally{
            f = t = 0;
        }
        if (op[0] & 5) throw op[1];
        return {
            value: op[0] ? op[1] : void 0,
            done: true
        };
    }
};
var $158ad1a38fb85e0e$var$__spreadArray = undefined && undefined.__spreadArray || function(to, from, pack) {
    if (pack || arguments.length === 2) {
        for(var i = 0, l = from.length, ar; i < l; i++)if (ar || !(i in from)) {
            if (!ar) ar = Array.prototype.slice.call(from, 0, i);
            ar[i] = from[i];
        }
    }
    return to.concat(ar || Array.prototype.slice.call(from));
};
var $158ad1a38fb85e0e$var$readyStates = [
    "CONNECTING",
    "OPEN",
    "CLOSING",
    "CLOSED"
];
var $158ad1a38fb85e0e$var$KEEP_ALIVE_INTERVAL = 5000;
var $158ad1a38fb85e0e$var$KEEP_ALIVE_TIMEOUT = 15000;
// client side code in soupSFU has a timeout of 15 seconds for command response
// 5 seconds seems reasonable that it provides roughly 3 retry attempts
var $158ad1a38fb85e0e$var$WEBSOCKET_CONNECTION_TIMEOUT = 150000;
var $158ad1a38fb85e0e$var$DEFAULT_RECONNECT_ATTEMPTS = 2;
var $158ad1a38fb85e0e$var$MAX_RECONNECT_ATTEMPTS = 10;
var $158ad1a38fb85e0e$var$DEFAULT_RECONNECT_INTERVAL = 1000;
var $158ad1a38fb85e0e$var$MAX_RECONNECT_INTERVAL = 30000;
var $158ad1a38fb85e0e$var$DEFAULT_RECONNECT_DECAY = 1.5;
var $158ad1a38fb85e0e$var$WEBSOCKET_TIMEOUT_CODE = 4100;
var $158ad1a38fb85e0e$var$SIG_CONNECTION_CANCELED = "SIG_CONNECTION_CANCELED";
var $158ad1a38fb85e0e$var$WEBSOCKET_ERROR = "WEBSOCKET_ERROR";
var $158ad1a38fb85e0e$var$LOG_LEVEL;
(function(LOG_LEVEL) {
    LOG_LEVEL[LOG_LEVEL["DEBUG"] = 0] = "DEBUG";
    LOG_LEVEL[LOG_LEVEL["ERROR"] = 1] = "ERROR";
    LOG_LEVEL[LOG_LEVEL["INFO"] = 2] = "INFO";
    LOG_LEVEL[LOG_LEVEL["WARN"] = 3] = "WARN";
})($158ad1a38fb85e0e$var$LOG_LEVEL || ($158ad1a38fb85e0e$var$LOG_LEVEL = {}));
var $158ad1a38fb85e0e$var$rWebSocket = /** @class */ function() {
    function rWebSocket(url, protocols) {
        this._closedManually = false;
        this._errored = false;
        this._rejected = false;
        this._timed_out = false;
        this._initialConnectionOk = false;
        this._ws = new WebSocket(url, protocols);
    }
    rWebSocket.prototype.addEventListener = function(type, listener) {
        this._ws.addEventListener(type, listener);
    };
    // Add other WebSocket methods as needed
    rWebSocket.prototype.close = function(code, reason) {
        this._ws.close(code, reason);
    };
    rWebSocket.prototype.send = function(data) {
        this._ws.send(data);
    };
    Object.defineProperty(rWebSocket.prototype, "url", {
        // Add getters for WebSocket properties
        get: function() {
            return this._ws.url;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(rWebSocket.prototype, "readyState", {
        get: function() {
            return this._ws.readyState;
        },
        enumerable: false,
        configurable: true
    });
    return rWebSocket;
}();
/**
 * Builds on top of Javascript Websockets
 *
 * This behaves like the Websocket library in every way, except if it fails to
 * connect or if it gets disconnected, it will try to reconnect depending on
 * the maximum number of reconnect attempts set. retry is not enabled for initial
 * connection. When initial connection fails it is best to check yourself before
 * you keep wreckin' yourself.
 *
 * It is API compatible, so when you have:
 *   ws = new WebSocket('ws://....');
 * you can replace with:
 *   ws = new ReconnectingWebSocket('ws://....');
 *
 * While it is API compatible with the NodeJS ws library, we provide the
 * following additional properties and events on the ReconnectingWebSocket.
 *
 * Events:
 *
 * connection-timeout
 * - Emitted when the web socket connection times out.
 *
 * reconnecting
 * - Emitted after a manual close of the web socket is done and before retrying
 *   the connection.
 *
 * reconnect-failed
 * - Emitted when the number of connection attempts exceeds the set number of
 *   reconnection attempts.
 *
 * keep-alive
 * - Emitted when the set keep alive interval elapses. This event may be used
 *   to have ping pong keep-alive mechanism for web socket health.
 *
 * Properties:
 *
 * keepAliveTimeout
 * - The timeout for keep-alive. Default: 15000
 *
 * keepAliveInterval
 * - The interval at which to emit keep-alive event. Default: 5000
 *
 * shouldRetryFn
 * - A callback function which should return boolean to determine if a web
 *   socket reconnection attempt should be made. When not set, connection is
 *   always retried.
 *
 * connectionTimeout
 * - The timeout interval for considering whether the connection timed out.
 *   Default: 20000 ms
 *
 * maxReconnectAttempts
 * - The maximum number of attempts to be made for reconnection. Default: 2
 *
 * reconnectInterval
 * - The interval to wait before attempting a reconnection. Default: 1000 ms
 */ var $158ad1a38fb85e0e$export$4f3d0ffd941ebefb = /** @class */ function(_super) {
    $158ad1a38fb85e0e$var$__extends(ReconnectingWebSocket, _super);
    function ReconnectingWebSocket(address, protocols, options) {
        if (options === void 0) options = {};
        var _a;
        var _this = _super.call(this) || this;
        if (!address) throw new Error("Need a valid WebSocket URL");
        _this._ws = null;
        _this._url = address;
        _this._protocols = protocols;
        _this._parseBlobToJson = (_a = options === null || options === void 0 ? void 0 : options.parseBlobToJson) !== null && _a !== void 0 ? _a : true;
        _this.init();
        return _this;
    }
    ReconnectingWebSocket.prototype.init = function() {
        this._keepAliveTimeout = $158ad1a38fb85e0e$var$KEEP_ALIVE_TIMEOUT;
        this._keepAliveInterval = $158ad1a38fb85e0e$var$KEEP_ALIVE_INTERVAL;
        this._disconnected = false;
        this._keepIntervalID = null;
        this._shouldRetryFn = null;
        this._connectionTimeout = $158ad1a38fb85e0e$var$WEBSOCKET_CONNECTION_TIMEOUT;
        this._reconnectAttempts = 0;
        this._allowedReconnectAttempts = $158ad1a38fb85e0e$var$DEFAULT_RECONNECT_ATTEMPTS;
        this._reconnectInterval = $158ad1a38fb85e0e$var$DEFAULT_RECONNECT_INTERVAL;
        this._maxReconnectInterval = $158ad1a38fb85e0e$var$MAX_RECONNECT_INTERVAL;
        this._reconnectDecay = $158ad1a38fb85e0e$var$DEFAULT_RECONNECT_DECAY;
    };
    ReconnectingWebSocket.prototype.connect = function() {
        return $158ad1a38fb85e0e$var$__awaiter(this, void 0, void 0, function() {
            var _this = this;
            return $158ad1a38fb85e0e$var$__generator(this, function(_a) {
                return [
                    2 /*return*/ ,
                    new Promise(function(resolve, reject) {
                        _this._disconnected = false;
                        _this.clearReconnectTimeout();
                        var ws = new $158ad1a38fb85e0e$var$rWebSocket(_this._url, _this._protocols);
                        _this.setConnectionTimeout();
                        ws.addEventListener("close", function(evt) {
                            var closeEvent = evt;
                            var code = ws._timed_out ? $158ad1a38fb85e0e$var$WEBSOCKET_TIMEOUT_CODE : closeEvent.code;
                            var reason = ws._timed_out ? "websocket connection timed out" : closeEvent.reason;
                            ws._timed_out = false;
                            if (!ws._closedManually && ws._initialConnectionOk) {
                                console.warn("signaling socket closed unexpectedly: ".concat(code).concat(reason ? " " + reason : ""));
                                _this._closeSocket();
                                _this.emit("close", code, reason);
                            } else _this.log("signaling socket closed");
                            if (!ws._closedManually && (ws._errored || ws._timed_out)) {
                                console.warn("signaling socket closed on error: ".concat(code).concat(reason ? " " + reason : ""));
                                if (!ws._rejected) {
                                    ws._rejected = true;
                                    var err = new Error("WebSocket connection error (".concat(code, "): ").concat(reason));
                                    err.name = $158ad1a38fb85e0e$var$WEBSOCKET_ERROR;
                                    reject(err);
                                }
                            }
                        });
                        ws.addEventListener("open", function(evt) {
                            _this.log("wss connection opened to", $158ad1a38fb85e0e$var$LOG_LEVEL.DEBUG, _this._url);
                            _this.clearConnectionTimeout();
                            // now that the timeout closes the socket, in theory this onopen
                            // callback should never happen in the first place, but seems
                            // harmless to leave these safeguards in
                            if (ws._rejected || ws._timed_out) return;
                            if (ws._closedManually || _this._ws && _this._ws !== ws) {
                                ws._rejected = true;
                                ws.close();
                                var err = Error("wss connection interrupted by disconnect or newer connection");
                                err.name = $158ad1a38fb85e0e$var$SIG_CONNECTION_CANCELED;
                                reject(err);
                                return;
                            }
                            ws._initialConnectionOk = _this._url;
                            _this._lastMsgRecvTime = Date.now();
                            if (_this._keepAliveInterval) _this._keepIntervalID = setInterval(function() {
                                return _this.checkSocketHealthAndSendKeepAlive();
                            }, _this._keepAliveInterval);
                            _this._ws = ws;
                            _this.emit("open");
                            resolve(ws);
                        });
                        ws.addEventListener("error", function(evt) {
                            // fyi: evt is an Event here, with 0 amount of helpful info. If there
                            //   happens to be info about the error, it's included in the
                            //   accompanying close event (because that make sense. shakes head)
                            //   SO. We do not reject here. Instead, we just set the _errored
                            //   flag on the socket so when the close event occurs, it knows to
                            //   reject the promise
                            if (!ws._closedManually) {
                                var wsTarget = evt.currentTarget;
                                _this.log("websocket error event: ".concat(wsTarget === null || wsTarget === void 0 ? void 0 : wsTarget.url));
                            }
                            ws._errored = true;
                        });
                        ws.addEventListener("message", function(msg) {
                            _this._handleMessage(msg);
                        });
                    })
                ];
            });
        });
    };
    ReconnectingWebSocket.prototype.setConnectionTimeout = function() {
        var _this = this;
        this._connectionTimeoutID = setTimeout(function() {
            return $158ad1a38fb85e0e$var$__awaiter(_this, void 0, void 0, function() {
                return $158ad1a38fb85e0e$var$__generator(this, function(_a) {
                    switch(_a.label){
                        case 0:
                            this.log("Connection reconnect attempt timed out.");
                            this.emit("connection-timeout");
                            this.clearConnectionTimeout();
                            return [
                                4 /*yield*/ ,
                                this._closeSocket()
                            ];
                        case 1:
                            _a.sent();
                            return [
                                2 /*return*/ 
                            ];
                    }
                });
            });
        }, this._connectionTimeout);
    };
    ReconnectingWebSocket.prototype.clearConnectionTimeout = function() {
        clearTimeout(this._connectionTimeoutID);
        this._connectionTimeoutID = undefined;
    };
    ReconnectingWebSocket.prototype.clearReconnectTimeout = function() {
        clearTimeout(this._reconnectTimeoutID);
        this._reconnectTimeoutID = undefined;
    };
    ReconnectingWebSocket.prototype.clearKeepAliveInterval = function() {
        if (this._keepIntervalID) {
            clearInterval(this._keepIntervalID);
            this._keepIntervalID = null;
        }
    };
    ReconnectingWebSocket.prototype.checkSocketHealthAndSendKeepAlive = function() {
        return $158ad1a38fb85e0e$var$__awaiter(this, void 0, void 0, function() {
            return $158ad1a38fb85e0e$var$__generator(this, function(_a) {
                switch(_a.label){
                    case 0:
                        if (!(this._ws && this._ws.readyState === WebSocket.OPEN)) return [
                            2 /*return*/ 
                        ];
                        if (!this._keepAliveTimeout || !this._keepAliveInterval) return [
                            2 /*return*/ 
                        ];
                        if (!(Date.now() - this._lastMsgRecvTime > this._keepAliveTimeout)) return [
                            3 /*break*/ ,
                            2
                        ];
                        this.log("Connection is stale, need to reconnect", $158ad1a38fb85e0e$var$LOG_LEVEL.WARN);
                        return [
                            4 /*yield*/ ,
                            this._closeSocket()
                        ];
                    case 1:
                        _a.sent();
                        return [
                            2 /*return*/ 
                        ];
                    case 2:
                        // Only emit the keep-alive event if we haven't sent anything else recently
                        if (Date.now() - this._lastMsgSendTime < this._keepAliveInterval) return [
                            2 /*return*/ 
                        ];
                        this.log("Emitting keep-alive", $158ad1a38fb85e0e$var$LOG_LEVEL.DEBUG);
                        this.emit("keep-alive");
                        return [
                            2 /*return*/ 
                        ];
                }
            });
        });
    };
    // We use the word manually here to imply the application using this code
    // or this code itself will decide to close the socket.
    ReconnectingWebSocket.prototype._closeSocket = function() {
        return $158ad1a38fb85e0e$var$__awaiter(this, void 0, void 0, function() {
            var shouldRetry, error_1;
            var _a;
            return $158ad1a38fb85e0e$var$__generator(this, function(_b) {
                switch(_b.label){
                    case 0:
                        this.log("Closing");
                        _b.label = 1;
                    case 1:
                        _b.trys.push([
                            1,
                            4,
                            ,
                            5
                        ]);
                        this.clearKeepAliveInterval();
                        this._lastMsgRecvTime = 0;
                        if (this._ws) {
                            this._ws._closedManually = true;
                            this._ws.close();
                        }
                        shouldRetry = ((_a = this._ws) === null || _a === void 0 ? void 0 : _a._initialConnectionOk) && this._shouldRetryFn && this._shouldRetryFn();
                        this._ws = null;
                        if (!shouldRetry) return [
                            3 /*break*/ ,
                            3
                        ];
                        this.log("Emitting reconnect", $158ad1a38fb85e0e$var$LOG_LEVEL.DEBUG);
                        this.emit("reconnecting");
                        return [
                            4 /*yield*/ ,
                            this.retryFailedConnection()
                        ];
                    case 2:
                        _b.sent();
                        _b.label = 3;
                    case 3:
                        return [
                            3 /*break*/ ,
                            5
                        ];
                    case 4:
                        error_1 = _b.sent();
                        this.log("Error while closing and retrying: ".concat(error_1), $158ad1a38fb85e0e$var$LOG_LEVEL.ERROR);
                        return [
                            3 /*break*/ ,
                            5
                        ];
                    case 5:
                        return [
                            2 /*return*/ 
                        ];
                }
            });
        });
    };
    ReconnectingWebSocket.prototype.retryFailedConnection = function() {
        return $158ad1a38fb85e0e$var$__awaiter(this, void 0, void 0, function() {
            var timeout;
            var _this = this;
            return $158ad1a38fb85e0e$var$__generator(this, function(_a) {
                if (this._reconnectAttempts < this._allowedReconnectAttempts) {
                    if (this._reconnectTimeoutID) {
                        this.log("Retry already scheduled");
                        return [
                            2 /*return*/ 
                        ];
                    }
                    this.log("Retrying failed connection");
                    timeout = // The timeout logic is taken from
                    // https://github.com/joewalnes/reconnecting-websocket
                    this._reconnectInterval * Math.pow(this._reconnectDecay, this._reconnectAttempts);
                    timeout = timeout > this._maxReconnectInterval ? this._maxReconnectInterval : timeout;
                    this.log("Reconnecting in ".concat(timeout / 1000, " seconds"));
                    this._reconnectAttempts += 1;
                    this._reconnectTimeoutID = setTimeout(function() {
                        return _this.connect();
                    }, timeout);
                } else {
                    this.log("Maximum connection retry attempts exceeded", $158ad1a38fb85e0e$var$LOG_LEVEL.ERROR);
                    this.emit("reconnect-failed");
                }
                return [
                    2 /*return*/ 
                ];
            });
        });
    };
    ReconnectingWebSocket.prototype.log = function(msg, log_level) {
        if (log_level === void 0) log_level = $158ad1a38fb85e0e$var$LOG_LEVEL.DEBUG;
        var args = [];
        for(var _i = 2; _i < arguments.length; _i++)args[_i - 2] = arguments[_i];
        switch(log_level){
            case $158ad1a38fb85e0e$var$LOG_LEVEL.DEBUG:
                console.debug.apply(console, $158ad1a38fb85e0e$var$__spreadArray([
                    "websocket: ".concat(msg)
                ], args, false));
                break;
            case $158ad1a38fb85e0e$var$LOG_LEVEL.ERROR:
                console.error.apply(console, $158ad1a38fb85e0e$var$__spreadArray([
                    "websocket: ".concat(msg)
                ], args, false));
                break;
            case $158ad1a38fb85e0e$var$LOG_LEVEL.WARN:
                console.warn.apply(console, $158ad1a38fb85e0e$var$__spreadArray([
                    "websocket: ".concat(msg)
                ], args, false));
                break;
            case $158ad1a38fb85e0e$var$LOG_LEVEL.INFO:
            default:
                console.log.apply(console, $158ad1a38fb85e0e$var$__spreadArray([
                    "websocket: ".concat(msg)
                ], args, false));
                break;
        }
    };
    ReconnectingWebSocket.prototype.send = function(data) {
        return $158ad1a38fb85e0e$var$__awaiter(this, void 0, void 0, function() {
            return $158ad1a38fb85e0e$var$__generator(this, function(_a) {
                try {
                    if (this._ws && this._ws.readyState === WebSocket.OPEN) {
                        this._lastMsgSendTime = Date.now();
                        this._ws.send(data);
                    } else this.log("Failed to send data, web socket not open.", $158ad1a38fb85e0e$var$LOG_LEVEL.ERROR);
                } catch (error) {
                    this.log("Failed to send data. ".concat(error), $158ad1a38fb85e0e$var$LOG_LEVEL.ERROR);
                }
                return [
                    2 /*return*/ 
                ];
            });
        });
    };
    ReconnectingWebSocket.prototype.close = function() {
        return $158ad1a38fb85e0e$var$__awaiter(this, void 0, void 0, function() {
            return $158ad1a38fb85e0e$var$__generator(this, function(_a) {
                try {
                    this.log("Closing websocket");
                    this._disconnected = true;
                    this.clearReconnectTimeout();
                    this._closeSocket();
                } catch (error) {
                    this.log("Failed to close websocket. ".concat(error));
                }
                return [
                    2 /*return*/ 
                ];
            });
        });
    };
    Object.defineProperty(ReconnectingWebSocket.prototype, "readyState", {
        get: function() {
            var _a, _b;
            return (_b = (_a = this._ws) === null || _a === void 0 ? void 0 : _a.readyState) !== null && _b !== void 0 ? _b : WebSocket.CLOSED;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(ReconnectingWebSocket.prototype, "url", {
        get: function() {
            return this._url;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(ReconnectingWebSocket.prototype, "keepAliveTimeout", {
        get: function() {
            return this._keepAliveTimeout;
        },
        set: function(keepAliveTimeout) {
            if (typeof keepAliveTimeout === "number") {
                this.log("Setting ACK freshness timeout to ".concat(keepAliveTimeout));
                this._keepAliveTimeout = keepAliveTimeout;
            }
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(ReconnectingWebSocket.prototype, "keepAliveInterval", {
        get: function() {
            return this._keepAliveInterval;
        },
        set: function(keepAliveInterval) {
            if (typeof keepAliveInterval === "number") {
                this.log("Setting keep-alive interval to ".concat(keepAliveInterval));
                this._keepAliveInterval = keepAliveInterval;
            }
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(ReconnectingWebSocket.prototype, "shouldRetryFn", {
        set: function(cb) {
            if (typeof cb === "function") this._shouldRetryFn = cb;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(ReconnectingWebSocket.prototype, "connectionTimeout", {
        get: function() {
            return this._connectionTimeout;
        },
        set: function(timeout) {
            if (typeof timeout === "number") this._connectionTimeout = timeout;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(ReconnectingWebSocket.prototype, "maxReconnectAttempts", {
        get: function() {
            return this._allowedReconnectAttempts;
        },
        set: function(attempts) {
            if (attempts > 0 && attempts < $158ad1a38fb85e0e$var$MAX_RECONNECT_ATTEMPTS) {
                this.log("Setting maximum connection retry attempts to ".concat(attempts));
                this._allowedReconnectAttempts = attempts;
            } else this._allowedReconnectAttempts = $158ad1a38fb85e0e$var$DEFAULT_RECONNECT_ATTEMPTS;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(ReconnectingWebSocket.prototype, "reconnectInterval", {
        get: function() {
            return this._reconnectInterval;
        },
        set: function(interval) {
            if (typeof interval === "number") this._reconnectInterval = interval < this._maxReconnectInterval ? interval : this._maxReconnectInterval;
        },
        enumerable: false,
        configurable: true
    });
    ReconnectingWebSocket.prototype._handleMessage = function(event) {
        return $158ad1a38fb85e0e$var$__awaiter(this, void 0, void 0, function() {
            var data, _parsePromise, msg;
            var _this = this;
            return $158ad1a38fb85e0e$var$__generator(this, function(_a) {
                switch(_a.label){
                    case 0:
                        this._lastMsgRecvTime = Date.now();
                        data = event.data;
                        _parsePromise = new Promise(function(resolve, reject) {
                            if (typeof data === "string") // Handle text message
                            resolve(data);
                            else if (data instanceof ArrayBuffer) {
                                // Handle binary message
                                var arrayBuffer = data;
                                // Parse the ArrayBuffer as needed
                                // Example: Convert ArrayBuffer to Uint8Array
                                resolve(new Uint8Array(arrayBuffer));
                            // Process the Uint8Array as needed
                            } else if (data instanceof Blob) {
                                if (!_this._parseBlobToJson) {
                                    resolve(data);
                                    return;
                                }
                                // Handle Blob message
                                var blob = data;
                                // Convert Blob to ArrayBuffer
                                var reader_1 = new FileReader();
                                reader_1.onload = function() {
                                    var text = reader_1.result;
                                    try {
                                        var json = JSON.parse(text);
                                        resolve(json);
                                    } catch (e) {
                                        console.error("Failed to parse JSON from Blob:", e);
                                    }
                                };
                                reader_1.readAsText(blob);
                            }
                        });
                        return [
                            4 /*yield*/ ,
                            _parsePromise
                        ];
                    case 1:
                        msg = _a.sent();
                        this.emit("message", msg);
                        return [
                            2 /*return*/ 
                        ];
                }
            });
        });
    };
    return ReconnectingWebSocket;
}((0, $fkNis$events.EventEmitter));
[
    "binaryType",
    "bufferedAmount",
    "extensions",
    "protocol",
    "readyState",
    "url",
    "keepAliveTimeout",
    "keepAliveInterval",
    "shouldRetryFn",
    "connectionTimeout",
    "maxReconnectAttempts",
    "reconnectInterval"
].forEach(function(property) {
    Object.defineProperty($158ad1a38fb85e0e$export$4f3d0ffd941ebefb.prototype, property, {
        enumerable: true
    });
});
[
    "CONNECTING",
    "OPEN",
    "CLOSING",
    "CLOSED"
].forEach(function(property) {
    Object.defineProperty($158ad1a38fb85e0e$export$4f3d0ffd941ebefb.prototype, property, {
        enumerable: true,
        value: $158ad1a38fb85e0e$var$readyStates.indexOf(property)
    });
});
[
    "CONNECTING",
    "OPEN",
    "CLOSING",
    "CLOSED"
].forEach(function(property) {
    Object.defineProperty($158ad1a38fb85e0e$export$4f3d0ffd941ebefb, property, {
        enumerable: true,
        value: $158ad1a38fb85e0e$var$readyStates.indexOf(property)
    });
});




// @generated message type with reflection information, may provide speed optimized methods
class $6abb1f384118d238$var$TextFrame$Type extends (0, $fkNis$protobuftsruntime.MessageType) {
    constructor(){
        super("pipecat.TextFrame", [
            {
                no: 1,
                name: "id",
                kind: "scalar",
                T: 4 /*ScalarType.UINT64*/ ,
                L: 0 /*LongType.BIGINT*/ 
            },
            {
                no: 2,
                name: "name",
                kind: "scalar",
                T: 9 /*ScalarType.STRING*/ 
            },
            {
                no: 3,
                name: "text",
                kind: "scalar",
                T: 9 /*ScalarType.STRING*/ 
            }
        ]);
    }
    create(value) {
        const message = globalThis.Object.create(this.messagePrototype);
        message.id = 0n;
        message.name = "";
        message.text = "";
        if (value !== undefined) (0, $fkNis$protobuftsruntime.reflectionMergePartial)(this, message, value);
        return message;
    }
    internalBinaryRead(reader, length, options, target) {
        let message = target ?? this.create(), end = reader.pos + length;
        while(reader.pos < end){
            let [fieldNo, wireType] = reader.tag();
            switch(fieldNo){
                case /* uint64 id */ 1:
                    message.id = reader.uint64().toBigInt();
                    break;
                case /* string name */ 2:
                    message.name = reader.string();
                    break;
                case /* string text */ 3:
                    message.text = reader.string();
                    break;
                default:
                    let u = options.readUnknownField;
                    if (u === "throw") throw new globalThis.Error(`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`);
                    let d = reader.skip(wireType);
                    if (u !== false) (u === true ? (0, $fkNis$protobuftsruntime.UnknownFieldHandler).onRead : u)(this.typeName, message, fieldNo, wireType, d);
            }
        }
        return message;
    }
    internalBinaryWrite(message, writer, options) {
        /* uint64 id = 1; */ if (message.id !== 0n) writer.tag(1, (0, $fkNis$protobuftsruntime.WireType).Varint).uint64(message.id);
        /* string name = 2; */ if (message.name !== "") writer.tag(2, (0, $fkNis$protobuftsruntime.WireType).LengthDelimited).string(message.name);
        /* string text = 3; */ if (message.text !== "") writer.tag(3, (0, $fkNis$protobuftsruntime.WireType).LengthDelimited).string(message.text);
        let u = options.writeUnknownFields;
        if (u !== false) (u == true ? (0, $fkNis$protobuftsruntime.UnknownFieldHandler).onWrite : u)(this.typeName, message, writer);
        return writer;
    }
}
const $6abb1f384118d238$export$78410ada03f6931b = new $6abb1f384118d238$var$TextFrame$Type();
// @generated message type with reflection information, may provide speed optimized methods
class $6abb1f384118d238$var$AudioRawFrame$Type extends (0, $fkNis$protobuftsruntime.MessageType) {
    constructor(){
        super("pipecat.AudioRawFrame", [
            {
                no: 1,
                name: "id",
                kind: "scalar",
                T: 4 /*ScalarType.UINT64*/ ,
                L: 0 /*LongType.BIGINT*/ 
            },
            {
                no: 2,
                name: "name",
                kind: "scalar",
                T: 9 /*ScalarType.STRING*/ 
            },
            {
                no: 3,
                name: "audio",
                kind: "scalar",
                T: 12 /*ScalarType.BYTES*/ 
            },
            {
                no: 4,
                name: "sample_rate",
                kind: "scalar",
                T: 13 /*ScalarType.UINT32*/ 
            },
            {
                no: 5,
                name: "num_channels",
                kind: "scalar",
                T: 13 /*ScalarType.UINT32*/ 
            },
            {
                no: 6,
                name: "pts",
                kind: "scalar",
                opt: true,
                T: 4 /*ScalarType.UINT64*/ ,
                L: 0 /*LongType.BIGINT*/ 
            }
        ]);
    }
    create(value) {
        const message = globalThis.Object.create(this.messagePrototype);
        message.id = 0n;
        message.name = "";
        message.audio = new Uint8Array(0);
        message.sampleRate = 0;
        message.numChannels = 0;
        if (value !== undefined) (0, $fkNis$protobuftsruntime.reflectionMergePartial)(this, message, value);
        return message;
    }
    internalBinaryRead(reader, length, options, target) {
        let message = target ?? this.create(), end = reader.pos + length;
        while(reader.pos < end){
            let [fieldNo, wireType] = reader.tag();
            switch(fieldNo){
                case /* uint64 id */ 1:
                    message.id = reader.uint64().toBigInt();
                    break;
                case /* string name */ 2:
                    message.name = reader.string();
                    break;
                case /* bytes audio */ 3:
                    message.audio = reader.bytes();
                    break;
                case /* uint32 sample_rate */ 4:
                    message.sampleRate = reader.uint32();
                    break;
                case /* uint32 num_channels */ 5:
                    message.numChannels = reader.uint32();
                    break;
                case /* optional uint64 pts */ 6:
                    message.pts = reader.uint64().toBigInt();
                    break;
                default:
                    let u = options.readUnknownField;
                    if (u === "throw") throw new globalThis.Error(`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`);
                    let d = reader.skip(wireType);
                    if (u !== false) (u === true ? (0, $fkNis$protobuftsruntime.UnknownFieldHandler).onRead : u)(this.typeName, message, fieldNo, wireType, d);
            }
        }
        return message;
    }
    internalBinaryWrite(message, writer, options) {
        /* uint64 id = 1; */ if (message.id !== 0n) writer.tag(1, (0, $fkNis$protobuftsruntime.WireType).Varint).uint64(message.id);
        /* string name = 2; */ if (message.name !== "") writer.tag(2, (0, $fkNis$protobuftsruntime.WireType).LengthDelimited).string(message.name);
        /* bytes audio = 3; */ if (message.audio.length) writer.tag(3, (0, $fkNis$protobuftsruntime.WireType).LengthDelimited).bytes(message.audio);
        /* uint32 sample_rate = 4; */ if (message.sampleRate !== 0) writer.tag(4, (0, $fkNis$protobuftsruntime.WireType).Varint).uint32(message.sampleRate);
        /* uint32 num_channels = 5; */ if (message.numChannels !== 0) writer.tag(5, (0, $fkNis$protobuftsruntime.WireType).Varint).uint32(message.numChannels);
        /* optional uint64 pts = 6; */ if (message.pts !== undefined) writer.tag(6, (0, $fkNis$protobuftsruntime.WireType).Varint).uint64(message.pts);
        let u = options.writeUnknownFields;
        if (u !== false) (u == true ? (0, $fkNis$protobuftsruntime.UnknownFieldHandler).onWrite : u)(this.typeName, message, writer);
        return writer;
    }
}
const $6abb1f384118d238$export$51d8721de3cbff8f = new $6abb1f384118d238$var$AudioRawFrame$Type();
// @generated message type with reflection information, may provide speed optimized methods
class $6abb1f384118d238$var$TranscriptionFrame$Type extends (0, $fkNis$protobuftsruntime.MessageType) {
    constructor(){
        super("pipecat.TranscriptionFrame", [
            {
                no: 1,
                name: "id",
                kind: "scalar",
                T: 4 /*ScalarType.UINT64*/ ,
                L: 0 /*LongType.BIGINT*/ 
            },
            {
                no: 2,
                name: "name",
                kind: "scalar",
                T: 9 /*ScalarType.STRING*/ 
            },
            {
                no: 3,
                name: "text",
                kind: "scalar",
                T: 9 /*ScalarType.STRING*/ 
            },
            {
                no: 4,
                name: "user_id",
                kind: "scalar",
                T: 9 /*ScalarType.STRING*/ 
            },
            {
                no: 5,
                name: "timestamp",
                kind: "scalar",
                T: 9 /*ScalarType.STRING*/ 
            }
        ]);
    }
    create(value) {
        const message = globalThis.Object.create(this.messagePrototype);
        message.id = 0n;
        message.name = "";
        message.text = "";
        message.userId = "";
        message.timestamp = "";
        if (value !== undefined) (0, $fkNis$protobuftsruntime.reflectionMergePartial)(this, message, value);
        return message;
    }
    internalBinaryRead(reader, length, options, target) {
        let message = target ?? this.create(), end = reader.pos + length;
        while(reader.pos < end){
            let [fieldNo, wireType] = reader.tag();
            switch(fieldNo){
                case /* uint64 id */ 1:
                    message.id = reader.uint64().toBigInt();
                    break;
                case /* string name */ 2:
                    message.name = reader.string();
                    break;
                case /* string text */ 3:
                    message.text = reader.string();
                    break;
                case /* string user_id */ 4:
                    message.userId = reader.string();
                    break;
                case /* string timestamp */ 5:
                    message.timestamp = reader.string();
                    break;
                default:
                    let u = options.readUnknownField;
                    if (u === "throw") throw new globalThis.Error(`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`);
                    let d = reader.skip(wireType);
                    if (u !== false) (u === true ? (0, $fkNis$protobuftsruntime.UnknownFieldHandler).onRead : u)(this.typeName, message, fieldNo, wireType, d);
            }
        }
        return message;
    }
    internalBinaryWrite(message, writer, options) {
        /* uint64 id = 1; */ if (message.id !== 0n) writer.tag(1, (0, $fkNis$protobuftsruntime.WireType).Varint).uint64(message.id);
        /* string name = 2; */ if (message.name !== "") writer.tag(2, (0, $fkNis$protobuftsruntime.WireType).LengthDelimited).string(message.name);
        /* string text = 3; */ if (message.text !== "") writer.tag(3, (0, $fkNis$protobuftsruntime.WireType).LengthDelimited).string(message.text);
        /* string user_id = 4; */ if (message.userId !== "") writer.tag(4, (0, $fkNis$protobuftsruntime.WireType).LengthDelimited).string(message.userId);
        /* string timestamp = 5; */ if (message.timestamp !== "") writer.tag(5, (0, $fkNis$protobuftsruntime.WireType).LengthDelimited).string(message.timestamp);
        let u = options.writeUnknownFields;
        if (u !== false) (u == true ? (0, $fkNis$protobuftsruntime.UnknownFieldHandler).onWrite : u)(this.typeName, message, writer);
        return writer;
    }
}
const $6abb1f384118d238$export$10b388c15a5cdc8a = new $6abb1f384118d238$var$TranscriptionFrame$Type();
// @generated message type with reflection information, may provide speed optimized methods
class $6abb1f384118d238$var$MessageFrame$Type extends (0, $fkNis$protobuftsruntime.MessageType) {
    constructor(){
        super("pipecat.MessageFrame", [
            {
                no: 1,
                name: "data",
                kind: "scalar",
                T: 9 /*ScalarType.STRING*/ 
            }
        ]);
    }
    create(value) {
        const message = globalThis.Object.create(this.messagePrototype);
        message.data = "";
        if (value !== undefined) (0, $fkNis$protobuftsruntime.reflectionMergePartial)(this, message, value);
        return message;
    }
    internalBinaryRead(reader, length, options, target) {
        let message = target ?? this.create(), end = reader.pos + length;
        while(reader.pos < end){
            let [fieldNo, wireType] = reader.tag();
            switch(fieldNo){
                case /* string data */ 1:
                    message.data = reader.string();
                    break;
                default:
                    let u = options.readUnknownField;
                    if (u === "throw") throw new globalThis.Error(`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`);
                    let d = reader.skip(wireType);
                    if (u !== false) (u === true ? (0, $fkNis$protobuftsruntime.UnknownFieldHandler).onRead : u)(this.typeName, message, fieldNo, wireType, d);
            }
        }
        return message;
    }
    internalBinaryWrite(message, writer, options) {
        /* string data = 1; */ if (message.data !== "") writer.tag(1, (0, $fkNis$protobuftsruntime.WireType).LengthDelimited).string(message.data);
        let u = options.writeUnknownFields;
        if (u !== false) (u == true ? (0, $fkNis$protobuftsruntime.UnknownFieldHandler).onWrite : u)(this.typeName, message, writer);
        return writer;
    }
}
const $6abb1f384118d238$export$bc3f45a6d434f14a = new $6abb1f384118d238$var$MessageFrame$Type();
// @generated message type with reflection information, may provide speed optimized methods
class $6abb1f384118d238$var$Frame$Type extends (0, $fkNis$protobuftsruntime.MessageType) {
    constructor(){
        super("pipecat.Frame", [
            {
                no: 1,
                name: "text",
                kind: "message",
                oneof: "frame",
                T: ()=>$6abb1f384118d238$export$78410ada03f6931b
            },
            {
                no: 2,
                name: "audio",
                kind: "message",
                oneof: "frame",
                T: ()=>$6abb1f384118d238$export$51d8721de3cbff8f
            },
            {
                no: 3,
                name: "transcription",
                kind: "message",
                oneof: "frame",
                T: ()=>$6abb1f384118d238$export$10b388c15a5cdc8a
            },
            {
                no: 4,
                name: "message",
                kind: "message",
                oneof: "frame",
                T: ()=>$6abb1f384118d238$export$bc3f45a6d434f14a
            }
        ]);
    }
    create(value) {
        const message = globalThis.Object.create(this.messagePrototype);
        message.frame = {
            oneofKind: undefined
        };
        if (value !== undefined) (0, $fkNis$protobuftsruntime.reflectionMergePartial)(this, message, value);
        return message;
    }
    internalBinaryRead(reader, length, options, target) {
        let message = target ?? this.create(), end = reader.pos + length;
        while(reader.pos < end){
            let [fieldNo, wireType] = reader.tag();
            switch(fieldNo){
                case /* pipecat.TextFrame text */ 1:
                    message.frame = {
                        oneofKind: "text",
                        text: $6abb1f384118d238$export$78410ada03f6931b.internalBinaryRead(reader, reader.uint32(), options, message.frame.text)
                    };
                    break;
                case /* pipecat.AudioRawFrame audio */ 2:
                    message.frame = {
                        oneofKind: "audio",
                        audio: $6abb1f384118d238$export$51d8721de3cbff8f.internalBinaryRead(reader, reader.uint32(), options, message.frame.audio)
                    };
                    break;
                case /* pipecat.TranscriptionFrame transcription */ 3:
                    message.frame = {
                        oneofKind: "transcription",
                        transcription: $6abb1f384118d238$export$10b388c15a5cdc8a.internalBinaryRead(reader, reader.uint32(), options, message.frame.transcription)
                    };
                    break;
                case /* pipecat.MessageFrame message */ 4:
                    message.frame = {
                        oneofKind: "message",
                        message: $6abb1f384118d238$export$bc3f45a6d434f14a.internalBinaryRead(reader, reader.uint32(), options, message.frame.message)
                    };
                    break;
                default:
                    let u = options.readUnknownField;
                    if (u === "throw") throw new globalThis.Error(`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`);
                    let d = reader.skip(wireType);
                    if (u !== false) (u === true ? (0, $fkNis$protobuftsruntime.UnknownFieldHandler).onRead : u)(this.typeName, message, fieldNo, wireType, d);
            }
        }
        return message;
    }
    internalBinaryWrite(message, writer, options) {
        /* pipecat.TextFrame text = 1; */ if (message.frame.oneofKind === "text") $6abb1f384118d238$export$78410ada03f6931b.internalBinaryWrite(message.frame.text, writer.tag(1, (0, $fkNis$protobuftsruntime.WireType).LengthDelimited).fork(), options).join();
        /* pipecat.AudioRawFrame audio = 2; */ if (message.frame.oneofKind === "audio") $6abb1f384118d238$export$51d8721de3cbff8f.internalBinaryWrite(message.frame.audio, writer.tag(2, (0, $fkNis$protobuftsruntime.WireType).LengthDelimited).fork(), options).join();
        /* pipecat.TranscriptionFrame transcription = 3; */ if (message.frame.oneofKind === "transcription") $6abb1f384118d238$export$10b388c15a5cdc8a.internalBinaryWrite(message.frame.transcription, writer.tag(3, (0, $fkNis$protobuftsruntime.WireType).LengthDelimited).fork(), options).join();
        /* pipecat.MessageFrame message = 4; */ if (message.frame.oneofKind === "message") $6abb1f384118d238$export$bc3f45a6d434f14a.internalBinaryWrite(message.frame.message, writer.tag(4, (0, $fkNis$protobuftsruntime.WireType).LengthDelimited).fork(), options).join();
        let u = options.writeUnknownFields;
        if (u !== false) (u == true ? (0, $fkNis$protobuftsruntime.UnknownFieldHandler).onWrite : u)(this.typeName, message, writer);
        return writer;
    }
}
const $6abb1f384118d238$export$b89a827e9254211a = new $6abb1f384118d238$var$Frame$Type();


class $49316c2028553492$export$4b2026f8e11b148a {
    serialize(data) {}
    serializeAudio(data, sampleRate, numChannels) {
        const pcmByteArray = new Uint8Array(data);
        const frame = (0, $6abb1f384118d238$export$b89a827e9254211a).create({
            frame: {
                oneofKind: "audio",
                audio: {
                    id: 0n,
                    name: "audio",
                    audio: pcmByteArray,
                    sampleRate: sampleRate,
                    numChannels: numChannels
                }
            }
        });
        return new Uint8Array((0, $6abb1f384118d238$export$b89a827e9254211a).toBinary(frame));
    }
    serializeMessage(msg) {
        const frame = (0, $6abb1f384118d238$export$b89a827e9254211a).create({
            frame: {
                oneofKind: "message",
                message: {
                    data: JSON.stringify(msg)
                }
            }
        });
        return new Uint8Array((0, $6abb1f384118d238$export$b89a827e9254211a).toBinary(frame));
    }
    async deserialize(data) {
        if (!(data instanceof Blob)) throw new Error("Unknown data type");
        const arrayBuffer = await data.arrayBuffer();
        const parsed = (0, $6abb1f384118d238$export$b89a827e9254211a).fromBinary(new Uint8Array(arrayBuffer)).frame;
        if (parsed.oneofKind === "audio") {
            const audioVector = Array.from(parsed.audio.audio);
            const uint8Array = new Uint8Array(audioVector);
            const int16Array = new Int16Array(uint8Array.buffer);
            return {
                type: "audio",
                audio: int16Array
            };
        } else if (parsed.oneofKind === "message") {
            const msg = JSON.parse(parsed.message.data);
            return {
                type: "message",
                message: msg
            };
        } else throw new Error("Unknown frame kind");
    }
}


class $bee70417e8ead9ed$export$de21836fc42c6f9c extends (0, $fkNis$pipecataiclientjs.Transport) {
    constructor({ serializer: serializer, recorderSampleRate: recorderSampleRate, playerSampleRate: playerSampleRate } = {
        serializer: new (0, $49316c2028553492$export$4b2026f8e11b148a)(),
        recorderSampleRate: $bee70417e8ead9ed$export$de21836fc42c6f9c.RECORDER_SAMPLE_RATE,
        playerSampleRate: $bee70417e8ead9ed$export$de21836fc42c6f9c.PLAYER_SAMPLE_RATE
    }){
        super();
        this.audioQueue = [];
        this._mediaManager = new (0, $1c088932741d88e6$export$c95c65abc5f47125)(true, true, undefined, undefined, 512, recorderSampleRate, playerSampleRate);
        this._mediaManager.setUserAudioCallback(this.handleUserAudioStream.bind(this));
        this._ws = null;
        this._serializer = serializer;
    }
    initialize(options, messageHandler) {
        this._options = options;
        this._callbacks = options.callbacks ?? {};
        this._onMessage = messageHandler;
        this._mediaManager.setRTVIOptions(options);
        this.state = "disconnected";
    }
    async initDevices() {
        this.state = "initializing";
        await this._mediaManager.initialize();
        this.state = "initialized";
    }
    async connect(authBundle, abortController) {
        this.state = "connecting";
        try {
            this._ws = this.initializeWebsocket(authBundle);
            await this._ws.connect();
            await this._mediaManager.connect();
            this.state = "connected";
            this._callbacks.onConnected?.();
        } catch (error) {
            const msg = `Failed to connect to websocket: ${error}`;
            (0, $fkNis$pipecataiclientjs.logger).error(msg);
            this.state = "error";
            throw new (0, $fkNis$pipecataiclientjs.TransportStartError)(msg);
        }
    }
    async disconnect() {
        this.state = "disconnecting";
        await this._mediaManager.disconnect();
        await this._ws?.close();
        this.state = "disconnected";
        this._callbacks.onDisconnected?.();
    }
    getAllMics() {
        return this._mediaManager.getAllMics();
    }
    getAllCams() {
        return this._mediaManager.getAllCams();
    }
    getAllSpeakers() {
        return this._mediaManager.getAllSpeakers();
    }
    async updateMic(micId) {
        return this._mediaManager.updateMic(micId);
    }
    updateCam(camId) {
        return this._mediaManager.updateCam(camId);
    }
    updateSpeaker(speakerId) {
        return this._mediaManager.updateSpeaker(speakerId);
    }
    get selectedMic() {
        return this._mediaManager.selectedMic;
    }
    get selectedSpeaker() {
        return this._mediaManager.selectedSpeaker;
    }
    enableMic(enable) {
        this._mediaManager.enableMic(enable);
    }
    get isMicEnabled() {
        return this._mediaManager.isMicEnabled;
    }
    get state() {
        return this._state;
    }
    set state(state) {
        if (this._state === state) return;
        this._state = state;
        this._callbacks.onTransportStateChanged?.(state);
    }
    get expiry() {
        return this._expiry;
    }
    tracks() {
        return this._mediaManager.tracks();
    }
    initializeWebsocket(authBundle) {
        console.log("Initializing websocket", authBundle);
        const ws = new (0, $158ad1a38fb85e0e$export$4f3d0ffd941ebefb)(`${authBundle.ws_url}`, undefined, {
            parseBlobToJson: false
        });
        // disabling the keep alive, there is no API for it inside Pipecat
        ws.keepAliveInterval = 0;
        ws.on("open", ()=>{
            (0, $fkNis$pipecataiclientjs.logger).debug("Websocket connection opened");
        });
        ws.on("message", async (data)=>{
            try {
                const parsed = await this._serializer.deserialize(data);
                if (parsed.type === "audio") this._mediaManager.bufferBotAudio(parsed.audio);
                else if (parsed.type === "message") {
                    if (parsed.message.label === "rtvi-ai") this._onMessage(parsed.message);
                }
            } catch (e) {
                (0, $fkNis$pipecataiclientjs.logger).error("Failed to deserialize incoming message", e);
            }
        });
        ws.on("error", (error)=>{
            this.connectionError(`websocket error: ${error}`);
        });
        ws.on("connection-timeout", ()=>{
            this.connectionError("websocket connection timed out");
        });
        ws.on("close", (code)=>{
            this.connectionError(`websocket connection closed. Code: ${code}`);
        });
        ws.on("reconnect-failed", ()=>{
            this.connectionError(`websocket reconnect failed`);
        });
        return ws;
    }
    sendReadyMessage() {
        this.state = "ready";
        this.sendMessage((0, $fkNis$pipecataiclientjs.RTVIMessage).clientReady());
    }
    handleUserAudioStream(data) {
        if (this.state === "ready") try {
            this.flushAudioQueue();
            this._sendAudioInput(data);
        } catch (error) {
            (0, $fkNis$pipecataiclientjs.logger).error("Error sending audio stream to websocket:", error);
            this.state = "error";
        }
        else this.audioQueue.push(data);
    }
    flushAudioQueue() {
        if (this.audioQueue.length <= 0) return;
        (0, $fkNis$pipecataiclientjs.logger).info("Will flush audio queue", this.audioQueue.length);
        while(this.audioQueue.length > 0){
            const queuedData = this.audioQueue.shift();
            if (queuedData) this._sendAudioInput(queuedData);
        }
    }
    sendRawMessage(message) {
        (0, $fkNis$pipecataiclientjs.logger).debug("Received raw message to send to Web Socket", message);
        const encoded = this._serializer.serialize(message);
        this._sendMsg(encoded);
    }
    sendMessage(message) {
        (0, $fkNis$pipecataiclientjs.logger).debug("Received message to send to Web Socket", message);
        const encoded = this._serializer.serializeMessage(message);
        this._sendMsg(encoded);
    }
    async _sendAudioInput(data) {
        try {
            const encoded = this._serializer.serializeAudio(data, $bee70417e8ead9ed$export$de21836fc42c6f9c.RECORDER_SAMPLE_RATE, 1);
            await this._sendMsg(encoded);
        } catch (e) {
            (0, $fkNis$pipecataiclientjs.logger).error("Error sending audio frame", e);
        }
    }
    async _sendMsg(msg) {
        if (!this._ws) {
            (0, $fkNis$pipecataiclientjs.logger).error("sendMsg called but WS is null");
            return;
        }
        if (this._ws.readyState !== WebSocket.OPEN) {
            (0, $fkNis$pipecataiclientjs.logger).error("attempt to send to closed socket");
            return;
        }
        if (!msg) return;
        try {
            await this._ws.send(msg);
        } catch (e) {
            (0, $fkNis$pipecataiclientjs.logger).error("sendMsg error", e);
        }
    }
    connectionError(errorMsg) {
        console.error(errorMsg);
        this.state = "error";
        this.disconnect();
    }
    // Not implemented
    enableScreenShare(enable) {
        (0, $fkNis$pipecataiclientjs.logger).error("startScreenShare not implemented for WebSocketTransport");
        throw new Error("Not implemented");
    }
    get isSharingScreen() {
        (0, $fkNis$pipecataiclientjs.logger).error("isSharingScreen not implemented for WebSocketTransport");
        return false;
    }
    enableCam(enable) {
        (0, $fkNis$pipecataiclientjs.logger).error("enableCam not implemented for WebSocketTransport");
        throw new Error("Not implemented");
    }
    get isCamEnabled() {
        (0, $fkNis$pipecataiclientjs.logger).error("isCamEnabled not implemented for WebSocketTransport");
        return false;
    }
    get selectedCam() {
        (0, $fkNis$pipecataiclientjs.logger).error("selectedCam not implemented for WebSocketTransport");
        throw new Error("Not implemented");
    }
}
$bee70417e8ead9ed$export$de21836fc42c6f9c.RECORDER_SAMPLE_RATE = 16000;
$bee70417e8ead9ed$export$de21836fc42c6f9c.PLAYER_SAMPLE_RATE = 24000;




class $36ab1bf4324e4b8b$export$44a8a077420336af {
    serialize(data) {
        return JSON.stringify(data);
    }
    serializeAudio(data, sampleRate, numChannels) {
        const pcmSamples = new Int16Array(data);
        const muLawSamples = (0, $fkNis$xlaw.mulaw).encode(pcmSamples);
        const base64Payload = this.arrayToBase64(muLawSamples);
        const twilioMessage = {
            event: "media",
            media: {
                payload: base64Payload
            }
        };
        return JSON.stringify(twilioMessage);
    }
    serializeMessage(msg) {
        // Twilio does not support RTVI messages, so just ignore them
        return null;
    }
    arrayToBase64(bytes) {
        let binary = "";
        for(let i = 0; i < bytes.byteLength; i++)binary += String.fromCharCode(bytes[i]);
        return btoa(binary);
    }
    base64ToUint8Array(base64) {
        const binaryString = atob(base64);
        const len = binaryString.length;
        const bytes = new Uint8Array(len);
        for(let i = 0; i < len; i++)bytes[i] = binaryString.charCodeAt(i);
        return bytes;
    }
    async deserialize(data) {
        const jsonMessage = JSON.parse(data); // Assuming 'data' is a JSON string
        if (jsonMessage.event === "clear") return {
            type: "raw",
            message: jsonMessage
        };
        else if (jsonMessage.event === "media") {
            // Deserialize 'media' event
            const payload = jsonMessage.media.payload;
            const serialized_data = this.base64ToUint8Array(payload);
            //const decoded_audio = this.ulawToPcm(serialized_data);
            const decoded_audio = (0, $fkNis$xlaw.mulaw).decode(serialized_data);
            return {
                type: "audio",
                audio: decoded_audio
            };
        } else // Deserialize other message types (assuming 'frame' has 'message' field)
        return {
            type: "message",
            message: jsonMessage.message
        };
    }
}




//# sourceMappingURL=index.js.map
